::: {.callout-tip}
## Application 23 : passer en production un mod√®le avec MLFlow

1. A partir du tableau de performance pr√©c√©dent,
choisir le mod√®le avec le F1 score maximal.
Acc√©der √† celui-ci.

Cr√©er un script dans `mlflow/predict.py` pour
illustrer l'utilisation d'un mod√®le
depuis MLFlow. Nous allons progressivement l'am√©liorer.

1. Copier-coller le
contenu ci-dessous
afin de se simplifier la cr√©ation de donn√©es en entr√©e
de notre code

```{.python filename="data/import_data.py"}
import data

@logger.catch
def create_data(
    sex: str = "female",
    age: float = 29.0,
    fare: float = 16.5,
    embarked: str = "S",
) -> str:
    """
    """

    df = pd.DataFrame(
        {
            "Sex": [sex],
            "Age": [age],
            "Fare": [fare],
            "Embarked": [embarked],
        }
    )

    return df
```

2. All√©ger, au passage, le code de l'API, en modifiant la fonction `predict` par celle-ci:

```{python}
from src.data.import_data import create_data

async def predict(
    sex: str = "female",
    age: float = 29.0,
    fare: float = 16.5,
    embarked: str = "S"
) -> str:
    """
    """

    df = create_data(
        sex=sex,
        age=age,
        fare=fare,
        embarked=embarked
    )

    prediction = "Survived üéâ" if int(model.predict(df)) == 1 else "Dead ‚ö∞Ô∏è"

    return prediction
```

3. Par le biais 

6. Cliquer sur votre meilleur mod√®le et introduire dans `mlflow/predict.py`
le morceau de code sugg√©r√©
par `MLFlow`, du type de celui-ci:

```{python}
#| eval: false
import mlflow
logged_model = #A CHANGER #<1>

# Load model as a PyFuncModel.
loaded_model = mlflow.pyfunc.load_model(logged_model)

# Predict on a Pandas DataFrame.
import pandas as pd
loaded_model.predict(pd.DataFrame(data))
```
1. _Hash_ du mod√®le

Lancer depuis la ligne de commande ce script et observer l'application obtenue.

:::

A ce stade, nous avons am√©lior√© la fiabilit√© de notre mod√®le car
nous utilisons le meilleur. N√©anmoins, celui-ci
n'est pas forc√©ment pratique √† r√©cup√©rer car nous utilisons
un _hash_ qui certes identifie de mani√®re unique notre mod√®le
mais pr√©sente l'inconv√©nient d'√™tre peu intelligible.
Nous allons passer de l'exp√©rimentation √† la mise
en production en s√©lectionnant explicitement notre meilleur mod√®le.

::: {.callout-tip}
## Application 23b : passer en production un mod√®le

1. Dans la page du mod√®le en question sur `MLFlow`, cliquer sur `Register model`
et le nommer `titanic`.
2. Aller dans l'onglet `Models` et observer le changement par rapport √† pr√©c√©demment.
3. Mettre √† jour le code dans `mlflow/predict.py` pour utiliser la version en
production :

```{.python filename = "mlflow/predict.py"}
model_name = "titanic"
model_version = 1
loaded_model = mlflow.pyfunc.load_model(
    model_uri=f"models:/{model_name}/{model_version}"
)
```

4. Tester cette application. Si celle-ci fonctionne,
modifier la r√©cup√©ration du mod√®le dans votre script d'API.

5. Tester en local cette API mise √† jour

```{.shell filename="terminal"}
uvicorn api.main:app --reload --host "0.0.0.0" --port 5000
```

6. Ajouter `mlflow` au `requirements.txt`

7. Mettre √† jour
les fichiers `.github/worflows/prod.yaml` et `kubernetes/deployment.yaml`
pour produire et utiliser le tag `v0.0.5`

```{python}
#| eval: false
#| filename: ".github/worflows/prod.yaml"
#| file: ".github/worflows/prod.yaml"

name: Construction image Docker

on:
  push:
    branches:
      - main
      - dev

jobs:
  docker:
    runs-on: ubuntu-latest
    steps:
      -
        name: Set up QEMU
        uses: docker/setup-qemu-action@v3
      -
        name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      -
        name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}
      -
        name: Build and push
        uses: docker/build-push-action@v5
        with:
          push: true
          tags: linogaliana/application:v0.0.7 #<1>
```
1. Modifier l'image ici


```{python}
#| eval: false
# Creating MLflow deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: titanicml
spec:
  replicas: 1
  selector:
    matchLabels:
      app: titanicml
  template:
    metadata:
      labels:
        app: titanicml
    spec:
      containers:
        - name: api
          image: linogaliana/application:v0.0.7 #<1>
          imagePullPolicy: Always
          env:
            - name: MLFLOW_TRACKING_URI
              value: https://user-{USERNAME}-mlflow.user.lab.sspcloud.fr #<2>
            - name: MLFLOW_MODEL_NAME
              value: titanic
            - name: MLFLOW_MODEL_VERSION
              value: "1"
          resources:
            limits:
              memory: "2Gi"
              cpu: "1000m"
```
1. Modifier l'image `Docker`
2. Modifier l'URL de `MLFlow`

:::

