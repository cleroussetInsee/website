{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Application\"\n",
        "description: |\n",
        "  Une application fil rouge pour illustrer l'intérêt d'appliquer graduellement les bonnes pratiques dans une optique de mise en production d'une application de data science.\n",
        "order: 10\n",
        "href: chapters/application.html\n",
        "image: /rocket.png\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "Dérouler les _slides_ ci-dessous ou [cliquer ici](https://ensae-reproductibilite.github.io/slides/#/title-slide)\n",
        "pour afficher les slides en plein écran.\n",
        "</summary>\n",
        "\n",
        "\n",
        "<div class=\"sourceCode\" id=\"cb1\"><pre class=\"sourceCode yaml code-with-copy\"><code class=\"sourceCode yaml\"></code><button title=\"Copy to Clipboard\" class=\"code-copy-button\"><i class=\"bi\"></i></button></pre><iframe class=\"sourceCode yaml code-with-copy\" src=\"https://ensae-reproductibilite.github.io/slides/#/title-slide\"></iframe></div>\n",
        "\n",
        "</details>\n",
        "\n",
        "L'objectif de cette mise en application est d'**illustrer les différentes étapes qui séparent la phase de développement d'un projet de celle de la mise en production**. Elle permettra de mettre en pratique les différents concepts présentés tout au long du cours.\n",
        "\n",
        "Celle-ci est un tutoriel pas à pas pour avoir un projet reproductible et disponible sous plusieurs livrables.\n",
        "Toutes les étapes ne sont pas indispensables à tous les projets de _data science_.\n",
        "\n",
        "Nous nous plaçons dans une situation initiale correspondant à la fin de la phase de développement d'un projet de data science.\n",
        "On a un _notebook_ un peu monolithique, qui réalise les étapes classiques d'un *pipeline* de *machine learning* :\n",
        "\n",
        "- Import de données ;\n",
        "- Statistiques descriptives et visualisations ;\n",
        "- *Feature engineering* ;\n",
        "- Entraînement d'un modèle ;\n",
        "- Evaluation du modèle.\n",
        "\n",
        "**L'objectif est d'améliorer le projet de manière incrémentale jusqu'à pouvoir le mettre en production, en le valorisant sous une forme adaptée.**\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "Illustration de notre point de départ\n",
        "</summary>\n",
        "![](/drawio/starting_point.png)\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "Illustration de l'horizon vers lequel on se dirige\n",
        "</summary>\n",
        "![](/drawio/end_point.png)\n",
        "</details>\n",
        "\n",
        "::: {.callout-important}\n",
        "Il est important de bien lire les consignes et d'y aller progressivement.\n",
        "Certaines étapes peuvent être rapides, d'autres plus fastidieuses ;\n",
        "certaines être assez guidées, d'autres vous laisser plus de liberté.\n",
        "Si vous n'effectuez pas une étape, vous risquez de ne pas pouvoir passer à\n",
        "l'étape suivante qui en dépend.\n",
        "\n",
        "Bien que l'exercice soit applicable sur toute configuration bien faite, nous\n",
        "recommandons de privilégier l'utilisation du [SSP Cloud](https://datalab.sspcloud.fr/home), où tous les\n",
        "outils nécessaires sont pré-installés et pré-configurés. Le service `VSCode`\n",
        "ne sera en effet que le point d'entrée pour l'utilisation d'outils plus exigeants\n",
        "sur le plan de l'infrastructure: _Argo_, _MLFLow_, etc.\n",
        ":::\n",
        "\n",
        "\n",
        "# Partie 0 : initialisation du projet\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Application préliminaire: forker le dépôt d'exemple\n",
        "\n",
        "Les premières étapes consistent à mettre en place son environnement de travail sur `Github`:\n",
        "\n",
        "- Générer un jeton d'accès (*token*) sur `GitHub` afin de permettre l'authentification en ligne de commande à votre compte.\n",
        "La procédure est décrite [ici](https://docs.sspcloud.fr/onyxia-guide/controle-de-version#creer-un-jeton-dacces-token).\n",
        "__Vous ne voyez ce jeton qu'une fois, ne fermez pas la page de suite__.\n",
        "\n",
        "- Mettez de côté ce jeton en l'enregistrant dans un gestionnaire de mot de passe ou dans\n",
        "l'espace _[\"Mon compte\"](https://datalab.sspcloud.fr/account/third-party-integration)_\n",
        "du `SSP Cloud`.\n",
        "\n",
        "- Forker le dépôt `Github` : [https://github.com/ensae-reproductibilite/application](https://github.com/ensae-reproductibilite/application) en faisant attention à une option :\n",
        "    + **Décocher la case _\"Copy the `main` branch only\"_** afin de copier également les _tags_ `Git` qui nous permettront de faire les _checkpoint_.\n",
        "\n",
        "\n",
        "<details>\n",
        "\n",
        "<summary>\n",
        "Ce que vous devriez voir sur la page de création du _fork_\n",
        "</summary>\n",
        "\n",
        "![](/fork-example.png)\n",
        "\n",
        "</details>\n",
        "\n",
        "Il est maintenant possible de ce lancer dans la création de l'environnement de travail:\n",
        "\n",
        "- Ouvrir un service `VSCode` sur le [SSP Cloud](https://datalab.sspcloud.fr/home). Vous pouvez aller\n",
        "dans la page `My Services` et cliquer sur `New service`. Sinon, vous\n",
        "pouvez initialiser la création du service en cliquant directement [ici](https://datalab.sspcloud.fr/launcher/ide/vscode-python?autoLaunch=false). __Modifier les options suivantes__:\n",
        "    + Dans l'onglet `Role`, sélectionner le rôle `Admin` ;\n",
        "    + Dans l'onglet `Networking`, cliquer sur _\"Enable a custom service port\"_ et laisser la valeur par défaut 5000 pour le numéro du port\n",
        "\n",
        "- Clôner __votre__ dépôt `Github` en utilisant le\n",
        "terminal depuis `Visual Studio` (`Terminal > New Terminal`) et\n",
        "en passant directement le token dans l'URL selon cette structure:\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git clone https://$TOKEN@github.com/$USERNAME/application.git\n",
        "```\n",
        "\n",
        "où `$TOKEN` et `$USERNAME` sont à remplacer, respectivement,\n",
        "par le jeton que vous avez généré précédemment et votre nom d'utilisateur.\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "# Partie 1 : qualité du script\n",
        "\n",
        "Cette première partie vise à **rendre le projet conforme aux bonnes pratiques** présentées dans le cours.\n",
        "\n",
        "Elle fait intervenir les notions suivantes :\n",
        "\n",
        "- Utilisation du **terminal** (voir [Linux 101](/chapters/linux-101.qmd)) ;\n",
        "- **Qualité du code** (voir [Qualité du code](/chapters/code-quality.qmd)) ;\n",
        "- **Architecture de projets** (voir [Architecture des projets](/chapters/projects-architecture.html)) ;\n",
        "- **Contrôle de version** avec `Git` (voir [Rappels `Git`](/chapters/git.qmd)) ;\n",
        "- **Travail collaboratif** avec `Git` et `GitHub` (voir [Rappels `Git`](/chapters/git.qmd)).\n",
        "\n",
        "\n",
        "Le plan de la partie est le suivant :\n",
        "\n",
        "1. S'assurer que le script fonctionne ;\n",
        "2. Nettoyer le code des scories formelles avec un _linter_ et un _formatter_ ;\n",
        "3. Paramétrisation du script ;\n",
        "4. Utilisation de fonctions.\n",
        "\n",
        "\n",
        "## Étape 1 : s'assurer que le script s'exécute correctement\n",
        "\n",
        "On va partir du fichier `notebook.py` qui reprend le contenu\n",
        "du _notebook_[^jupytext] mais dans un script classique.\n",
        "Le travail de nettoyage en sera facilité.\n",
        "\n",
        "[^jupytext]: L'export dans un script `.py` a été fait\n",
        "        directement depuis `VSCode`. Comme\n",
        "        cela n'est pas vraiment l'objet du cours, nous passons cette étape et fournissons\n",
        "        directement le script expurgé du texte intermédiaire. Mais n'oubliez\n",
        "        pas que cette démarche, fréquente quand on a démarré sur un _notebook_ et\n",
        "        qu'on désire consolider en faisant la transition vers des\n",
        "        scripts, nécessite d'être attentif pour ne pas risquer de faire une erreur.\n",
        "\n",
        "La première étape est simple, mais souvent oubliée : **vérifier que le code fonctionne correctement**.\n",
        "Pour cela, nous recommandons de faire un aller-retour entre le script ouvert dans `VSCode`\n",
        "et un terminal pour le lancer.\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Application 1: corriger les erreurs\n",
        "\n",
        "- Ouvrir dans `VSCode` le script `titanic.py` ;\n",
        "- Exécuter le script en ligne de commande (`python titanic.py`)[^interactivite] pour détecter les erreurs ;\n",
        "- Corriger les deux erreurs qui empêchent la bonne exécution ;\n",
        "- Vérifier le fonctionnement du script en utilisant la ligne de commande:\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "python titanic.py\n",
        "```\n",
        "\n",
        "Le code devrait afficher des sorties.\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "Aide sur les erreurs rencontrées\n",
        "</summary>\n",
        "\n",
        "La première erreur rencontrée est une alerte `FileNotFoundError`,\n",
        "la seconde est liée à un _package_. \n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "Il est maintenant temps de *commit* les changements effectués avec `Git`[^2] :\n",
        "\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git add titanic.py\n",
        "git commit -m \"Corrige l'erreur qui empêchait l'exécution\"\n",
        "git push\n",
        "```\n",
        "\n",
        "<!---- \n",
        "Temps estimé: 3mn\n",
        "------>\n",
        "\n",
        ":::\n",
        "\n",
        "[^interactivite]: Il est également possible avec `VSCode` d'exécuter le script ligne à ligne\n",
        "de manière interactive ligne à ligne (<kbd>MAJ</kbd>+<kbd>ENTER</kbd>). Néanmoins, cela nécessite\n",
        "de s'assurer que le _working directory_ de votre console interactive est le bon. Celle-ci se\n",
        "lance selon les paramètres préconfigurés de `VSCode` et les votres ne sont peut-être pas les\n",
        "mêmes que les notres. Vous pouvez changer le _working directory_ dans le script\n",
        "en utilisant le _package_ `os` mais peut-être allez vous découvrir ultérieurement qu'il\n",
        "y a de meilleures pratiques...\n",
        "[^2]: Essayez de *commit* vos changements à chaque étape de l'exercice, c'est une bonne habitude à prendre.\n",
        "\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli1\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Étape 2: utiliser un _linter_ puis un _formatter_\n",
        "\n",
        "On va maintenant améliorer la qualité de notre code en appliquant les standards communautaires.\n",
        "Pour cela, on va utiliser le *linter* classique [`PyLint`](https://pylint.readthedocs.io/en/latest/)\n",
        "et le _formatter_ [`Black`](https://github.com/psf/black).\n",
        "Si vous désirez un outil deux en un, il est possible d'utiliser [`Ruff`](https://github.com/astral-sh/ruff-vscode)\n",
        "en complément ou substitut.\n",
        "\n",
        "Ce nettoyage automatique du code permettra, au passage, de restructurer notre\n",
        "script de manière plus naturelle.\n",
        "\n",
        "::: {.callout-important}\n",
        "[`PyLint`](https://pylint.readthedocs.io/en/latest/) et [`Black`](https://black.readthedocs.io/en/stable/)\n",
        "sont des _packages_ `Python` qui\n",
        "s'utilisent principalement en ligne de commande.\n",
        "\n",
        "Si vous avez une erreur qui suggère\n",
        "que votre terminal ne connait pas [`PyLint`](https://pylint.readthedocs.io/en/latest/)\n",
        "ou [`Black`](https://black.readthedocs.io/en/stable/),\n",
        "n'oubliez pas d'exécuter la commande `pip install pylint` ou `pip install black`.\n",
        ":::\n",
        "\n",
        "\n",
        "Le _linter_ renvoie alors une série d'irrégularités,\n",
        "en précisant à chaque fois la ligne de l'erreur et le message d'erreur associé (ex : mauvaise identation).\n",
        "Il renvoie finalement une note sur 10,\n",
        "qui estime la qualité du code à l'aune des standards communautaires évoqués\n",
        "dans la partie [Qualité du code](/chapters/code-quality.html).\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Application 2: rendre lisible le script\n",
        "\n",
        "- Diagnostiquer et évaluer la qualité de `titanic.py` avec [`PyLint`](https://pylint.readthedocs.io/en/latest/). Regarder la note obtenue.\n",
        "- Utiliser `black titanic.py --diff --color` pour observer les changements de forme que va induire l'utilisation du _formatter_ [`Black`](https://black.readthedocs.io/en/stable/). Cette étape n'applique pas les modifications, elle ne fait que vous les montrer.\n",
        "- Appliquer le _formatter_ [`Black`](https://black.readthedocs.io/en/stable/)\n",
        "- Réutiliser [`PyLint`](https://pylint.readthedocs.io/en/latest/) pour diagnostiquer l'amélioration de la qualité du script et le travail qui reste à faire. \n",
        "- Comme la majorité du travail restant est à consacrer aux imports:\n",
        "    - Mettre tous les _imports_ ensemble en début de script\n",
        "    - Retirer les _imports_ redondants en s'aidant des diagnostics de votre éditeur\n",
        "    - Réordonner les _imports_ si [`PyLint`](https://pylint.readthedocs.io/en/latest/) vous indique de le faire\n",
        "    - Corriger les dernières fautes formelles suggérées par [`PyLint`](https://pylint.readthedocs.io/en/latest/)\n",
        "- Délimiter des parties dans votre code pour rendre sa structure plus lisible. Si des parties vous semblent être dans le désordre, vous pouvez réordonner le script (mais n'oubliez pas de le tester)\n",
        "\n",
        "<!-----\n",
        "Temps test Julien: 22mn\n",
        "------>\n",
        ":::\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli2\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "Le code est maintenant lisible, il obtient à ce stade une note formelle proche de 10.\n",
        "Mais il n'est pas encore totalement intelligible ou fiable.\n",
        "Il y a notamment\n",
        "quelques redondances de code auxquelles nous allons nous attaquer par la suite.\n",
        "Néanmoins, avant cela, occupons-nous de mieux gérer certains paramètres du script:\n",
        "jetons d'API et chemin des fichiers.\n",
        "\n",
        "\n",
        "## Étape 3: gestion des paramètres\n",
        "\n",
        "L'exécution du code et les résultats obtenus\n",
        "dépendent de certains paramètres définis dans le code. L'étude de résultats\n",
        "alternatifs, en jouant sur\n",
        "des variantes des (hyper)paramètres, est à ce stade compliquée\n",
        "car il est nécessaire de parcourir le code pour trouver\n",
        "ces paramètres. De plus, certains paramètres personnels\n",
        "comme des jetons\n",
        "d'API ou des mots de passe n'ont pas vocation à\n",
        "être présents dans le code.\n",
        "\n",
        "Il est plus judicieux de considérer ces paramètres comme des\n",
        "variables d'entrée du script. Cela peut être fait de deux\n",
        "manières:\n",
        "\n",
        "1. Avec des __arguments optionnels__ appelés depuis la ligne de commande _(Application 3a)_.\n",
        "Cela peut être pratique pour mettre en oeuvre des tests automatisés mais\n",
        "n'est pas forcément pertinent pour toutes les variables. Nous allons montrer\n",
        "cet usage avec le nombre d'arbres de notre _random forest_ ;\n",
        "2. En utilisant un __fichier de configuration__ dont les valeurs sont importées dans\n",
        "le script principal _(Application 3b)_.\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "Un exemple de définition d'un argument pour l'utilisation en ligne de commande\n",
        "</summary>\n",
        "\n",
        "```{.python filename=\"prenom.py\"}\n",
        "import argparse\n",
        "parser = argparse.ArgumentParser(description=\"Qui êtes-vous?\")\n",
        "parser.add_argument(\n",
        "    \"--prenom\", type=str, default=\"Toto\", help=\"Un prénom à afficher\"\n",
        ")\n",
        "args = parser.parse_args()\n",
        "print(args.prenom)\n",
        "```\n",
        "\n",
        "Exemples d'utilisations en ligne de commande\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "python prenom.py\n",
        "python prenom.py --prenom \"Zinedine\"\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Application 3a: Paramétrisation du script\n",
        "\n",
        "1. En s'inspirant de l'exemple ci-dessus 👆️,\n",
        "créer une variable `n_trees` qui peut éventuellement être paramétrée en ligne de commande\n",
        "et dont la valeur par défaut est 20 ;\n",
        "2. Tester cette paramétrisation en ligne de commande avec la valeur par défaut\n",
        "puis 2, 10 et 50 arbres.\n",
        ":::\n",
        "\n",
        "L'exercice suivant permet de mettre en application le fait de paramétriser\n",
        "un script en utilisant des variables définies dans un fichier YAML.\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Application 3b: La configuration dans un fichier dédié\n",
        "\n",
        "1. Installer le package `python-dotenv` que nous allons utiliser pour charger notre jeton d'API à partir d'une variable d'environnement.\n",
        "2. A partir de l'exemple de la [documentation](https://pypi.org/project/python-dotenv/), utiliser la fonction `load_dotenv` pour charger dans `Python` nos variables d'environnement à partir d'un fichier (vous pouvez le créer mais ne pas le remplir encore avec les valeurs voulues, ce sera fait ensuite)\n",
        "3. Créer la variable et vérifier la sortie de `Python` en faisant tourner `titanic.py` en ligne de commande\n",
        "\n",
        "\n",
        "```{.python filename=\"titanic.py\"}\n",
        "jeton_api = os.environ.get(\"JETON_API\", \"\")\n",
        "\n",
        "if jeton_api.startswith(\"$\"):\n",
        "    print(\"API token has been configured properly\")\n",
        "else:\n",
        "    print(\"API token has not been configured\")\n",
        "```\n",
        "\n",
        "4. Maintenant introduire la valeur voulue pour le jeton d'API dans le fichier d'environnement lu par `dotenv`\n",
        "5. S'il n'existe pas déjà, créer un fichier `.gitignore` (cf. [Chapitre `Git`](/chapters/git.qmd)). Ajouter dans ce fichier `.env` car il ne faut pas committer ce fichier. Au passage ajouter `__pycache__/` au `.gitignore`[^pycache], cela\n",
        "évitera d'avoir à le faire ultérieurement ;\n",
        "1. Créer un fichier `README.md` où vous indiquez qu'il faut créer un fichier `.env` pour\n",
        "pouvoir utiliser l'API.\n",
        "\n",
        "[^fileexist]: Ici, le jeton d'API n'est pas indispensable pour que le code\n",
        "    fonctionne. Afin d'éviter une erreur non nécessaire\n",
        "    lorsqu'on automatisera le processus, on peut\n",
        "    créer une condition qui vérifie la présence ou non de ce fichier.\n",
        "    Le script reste donc reproductible même pour un utilisateur n'ayant pas le fichier\n",
        "    `secrets.yaml`.\n",
        "\n",
        "[^pycache]: Il est normal d'avoir des dossiers `__pycache__` qui traînent en local : ils se créent automatiquement à l'exécution d'un script en `Python`. Néanmoins, il ne faut pas associer ces fichiers à `Git`, voilà pourquoi on les ajoute au `.gitignore`.\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli3\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Étape 4 : Privilégier la programmation fonctionnelle\n",
        "\n",
        "Nous allons **mettre en fonctions les parties importantes de l'analyse**.\n",
        "Ceci facilitera l'étape ultérieure de modularisation de notre projet.\n",
        "\n",
        "Cet exercice étant chronophage, il n'est __pas obligatoire de le réaliser en entier__. L'important est de\n",
        "comprendre la démarche et d'adopter fréquemment une approche fonctionnelle[^POO]. Pour obtenir\n",
        "une chaine entièrement fonctionnalisée, vous pouvez reprendre le _checkpoint_.\n",
        "\n",
        "[^POO]: Nous proposons ici d'adopter le principe de la __programmation fonctionnelle__. Pour encore fiabiliser\n",
        "un processus, il serait possible d'adopter le paradigme de la __programmation orientée objet (POO)__. Celle-ci est\n",
        "plus rebutante et demande plus de temps au développeur. L'arbitrage coût-avantage est négatif pour notre\n",
        "exemple, nous proposons donc de nous en passer. Néanmoins, pour une mise en production réelle d'un modèle,\n",
        "il est recommandé de l'adopter. C'est d'ailleurs obligatoire avec des [_pipelines_ `scikit`](https://pythonds.linogaliana.fr/pipeline-scikit/).\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Application 4: adoption des standards de programmation fonctionnelle\n",
        "\n",
        "Cette application peut être chronophage, vous pouvez aller plus ou moins\n",
        "loin dans la fonctionalisation de votre script en fonction du temps dont vous\n",
        "disposez.\n",
        "\n",
        "* Créer une fonction générique pour réduire la redondance de code\n",
        " dans l'étape d'exploration des données où on utilise `split` ;\n",
        "* Créer une fonction qui réalise le *split train/test* en fonction d'un paramètre représentant la proportion de l'échantillon de test\n",
        "et d'arguments optionnels sur les chemins d'écriture des deux échantillons en csv.\n",
        "* Créer une fonction qui intègre les différentes étapes du _pipeline_ (preprocessing et définition du modèle). Cette fonction prend\n",
        "en paramètre le nombre d'arbres (argument obligatoire) et des arguments optionnels supplémentaires (les colonnes sur lesquelles s'appliquent les différentes étapes du _pipeline_, `max_depth` et `max_features`).\n",
        "* Créer une fonction d'évaluation renvoyant le score obtenu et la matrice de confusion, à l'issue d'une estimation (mais cette estimation est faite en amont de la fonction, pas au sein de celle-ci)\n",
        "- Déplacer toutes les fonctions ensemble, en début de script. Si besoin, ajouter des paramètres à votre fichier d'environnement pour créer de nouvelles variables comme les chemins des données.\n",
        ":::\n",
        "\n",
        "[^notepandas]: Au passage vous pouvez noter que mauvaises pratiques discutables,\n",
        "    peuvent\n",
        "    être corrigées, notamment l'utilisation excessive de `apply` là où\n",
        "    il serait possible d'utiliser des méthodes embarquées par `Pandas`.\n",
        "    Cela est plutôt de l'ordre du bon style de programmation que de la\n",
        "    qualité formelle du script. Ce n'est donc pas obligatoire mais c'est mieux.\n",
        "\n",
        "\n",
        "::: {.callout-important}\n",
        "Le fait d'appliquer des fonctions a déjà amélioré la fiabilité du processus\n",
        "en réduisant le nombre d'erreurs de copier-coller. Néanmoins, pour vraiment\n",
        "fiabiliser le processus, il faudrait utiliser un _pipeline_ de transformations\n",
        "de données.\n",
        "\n",
        "Ceci n'est pas encore au programme du cours mais le sera dans une prochaine\n",
        "version.\n",
        ":::\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli4\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "Cela ne se remarque pas encore vraiment car nous avons de nombreuses définitions de fonctions\n",
        "mais notre chaine de production est beaucoup plus\n",
        "concise (le script fait environ 300 lignes dont 250 de définitions de fonctions génériques).\n",
        "Cette auto-discipline facilitera grandement\n",
        "les étapes ultérieures. Cela aurait été néanmoins beaucoup moins coûteux en temps d'adopter\n",
        "ces bons gestes de manière plus précoce.\n",
        "\n",
        "\n",
        "# Partie 2 : adoption d'une structure modulaire {#partie2}\n",
        "\n",
        "Dans la partie précédente,\n",
        "on a appliqué de manière incrémentale de nombreuses bonnes pratiques vues tout au long du cours.\n",
        "Ce faisant, on s'est déjà considérablement rapprochés d'un\n",
        "possible partage du code : celui-ci est lisible et intelligible.\n",
        "Le code est proprement versionné sur un\n",
        "dépôt `GitHub`.\n",
        "Cependant, le projet est encore perfectible: il est encore difficile de rentrer\n",
        "dedans si on ne sait pas exactement ce qu'on recherche. L'objectif de cette partie\n",
        "est d'isoler les différentes étapes de notre _pipeline_.\n",
        "Outre le gain de clarté pour notre projet, nous économiserons beaucoup de peines\n",
        "pour la mise en production ultérieure de notre modèle.\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "Illustration de l'état actuel du projet\n",
        "</summary>\n",
        "![](/schema_post_appli4.png)\n",
        "</details>\n",
        "\n",
        "Dans cette partie nous allons continuer les améliorations\n",
        "incrémentales de notre projet avec les étapes suivantes:\n",
        "\n",
        "1. Modularisation du code `Python` pour séparer les différentes\n",
        "étapes de notre _pipeline_ ;\n",
        "2. Adopter une structure standardisée pour notre projet afin\n",
        "d'autodocumenter l'organisation de celui-ci ;\n",
        "3. Documenter les _packages_ indispensables à l'exécution du code ;\n",
        "4. Stocker les données dans un environnement adéquat\n",
        "afin de continuer la démarche de séparer conceptuellement les données du code en de la configuration.\n",
        "\n",
        "\n",
        "## Étape 1 : modularisation\n",
        "\n",
        "Nous allons profiter de la modularisation pour adopter une structure\n",
        "applicative pour notre code. Celui-ci n'étant en effet plus lancé\n",
        "que depuis la ligne de commande, on peut considérer qu'on construit\n",
        "une application générique où un script principal (`main.py`)\n",
        "encapsule des éléments issus d'autres scripts `Python`.\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Application 5: modularisation\n",
        "\n",
        "- Déplacer les fonctions dans une série de fichiers dédiés:\n",
        "    +  `import_data.py`: fonctions d'import et d'exploration de données \n",
        "    +  `build_features.py`: fonctions regroupant la définition des échantillons d'apprentissage et de test ainsi que le _pipeline_ \n",
        "    +  `train_evaluate.py`: fonctions d'évaluation du modèle\n",
        "- Spécifier les dépendances (i.e. les packages à importer)\n",
        "dans les modules pour que ceux-ci puissent s'exécuter indépendamment ;\n",
        "- Renommer `titanic.py` en `main.py` pour suivre la convention de nommage des projets `Python` ;\n",
        "- Importer les fonctions nécessaires à partir des modules.\n",
        "- Vérifier que tout fonctionne bien en exécutant le _script_ `main` à partir de la ligne de commande :\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "python main.py\n",
        "```\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli5\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Étape 2 : adopter une architecture standardisée de projet\n",
        "\n",
        "On dispose maintenant d'une application `Python` fonctionnelle.\n",
        "Néanmoins, le projet est certes plus fiable mais sa structuration\n",
        "laisse à désirer et il serait difficile de rentrer à nouveau\n",
        "dans le projet dans quelques temps.\n",
        "\n",
        "<details>\n",
        "<summary>Etat actuel du projet 🙈</summary>\n",
        "\n",
        "```\n",
        "├── .gitignore\n",
        "├── data.csv\n",
        "├── train.csv\n",
        "├── test.csv\n",
        "├── README.md\n",
        "├── config.yaml\n",
        "├── import_data.py\n",
        "├── build_features.py\n",
        "├── train_evaluate.py\n",
        "├── titanic.ipynb\n",
        "└── main.py\n",
        "```\n",
        "\n",
        "\n",
        "</details>\n",
        "\n",
        "Comme cela est expliqué dans la\n",
        "partie [Structure des projets](/chapters/projects-architecture.html),\n",
        "on va adopter une structure certes arbitraire mais qui va\n",
        "faciliter l'autodocumentation de notre projet. De plus, une telle structure va faciliter des évolutions optionnelles\n",
        "comme la _packagisation_ du projet. Passer d'une structure modulaire\n",
        "bien faite à un _package_ est quasi-immédiat en `Python`.\n",
        "\n",
        "On va donc modifier l'architecture de notre projet pour la rendre plus standardisée.\n",
        "Pour cela, on va s'inspirer des structures\n",
        "[`cookiecutter`](https://cookiecutter.readthedocs.io/en/stable/)\n",
        "qui génèrent des _templates_ de projet. En l'occurrence\n",
        "notre source d'inspiration sera le [_template datascience_](https://drivendata.github.io/cookiecutter-data-science/)\n",
        "issu d'un effort communautaire.\n",
        "\n",
        "::: {.callout-note}\n",
        "L'idée de [`cookiecutter`](https://cookiecutter.readthedocs.io/en/stable/) est de proposer des _templates_ que l'on utilise pour __initialiser__ un projet, afin de bâtir à l'avance une structure évolutive. La syntaxe à utiliser dans ce cas est la suivante :\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "pip install cookiecutter\n",
        "cookiecutter https://github.com/drivendata/cookiecutter-data-science\n",
        "```\n",
        "\n",
        "Ici, on a déjà un projet, on va donc faire les choses dans l'autre sens : on va s'inspirer de la structure proposée afin de réorganiser celle de notre projet selon les standards communautaires.\n",
        ":::\n",
        "\n",
        "En s'inspirant du _cookiecutter data science_\n",
        "on va adopter la structure suivante:\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "Structure recommandée\n",
        "</summary>\n",
        "\n",
        "```\n",
        "application\n",
        "├── main.py\n",
        "├── README.md\n",
        "├── data\n",
        "│   ├── raw\n",
        "│   │   └── data.csv\n",
        "│   └── derived\n",
        "│       ├── test.csv\n",
        "│       └── train.csv\n",
        "├── configuration\n",
        "│   └── config.yaml\n",
        "├── notebooks\n",
        "│   └── titanic.ipynb\n",
        "└── src\n",
        "    ├── data\n",
        "    │   └── import_data.py\n",
        "    ├── pipeline\n",
        "    │   └── build_pipeline.py\n",
        "    └── models\n",
        "        └── train_evaluate.py\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "\n",
        "## Application 6: adopter une structure lisible\n",
        "\n",
        "- _(optionnel)_ Analyser et comprendre la [structure de projet](https://drivendata.github.io/cookiecutter-data-science/#directory-structure) proposée par le template ;\n",
        "- Modifier l'arborescence du projet selon le modèle ;\n",
        "- Mettre à jour l'import des dépendances, le fichier de configuration et `main.py` avec les nouveaux chemins ;\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli6\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Étape 3: mieux tracer notre chaine de production\n",
        "\n",
        "### Indiquer l'environnement minimal de reproductibilité\n",
        "\n",
        "Le script `main.py` nécessite un certain nombre de packages pour\n",
        "être fonctionnel. Chez vous les packages nécessaires sont\n",
        "bien sûr installés mais êtes-vous assuré que c'est le cas\n",
        "chez la personne qui testera votre code ?\n",
        "\n",
        "Afin de favoriser la portabilité du projet,\n",
        "il est d'usage de _\"fixer l'environnement\"_,\n",
        "c'est-à-dire d'indiquer dans un fichier toutes les dépendances utilisées ainsi que leurs version.\n",
        "Nous proposons de créer un fichier `requirements.txt` minimal, sur lequel nous reviendrons\n",
        "dans la partie consacrée aux environnements reproductibles.\n",
        "\n",
        "Le fichier `requirements.txt` est conventionnellement localisé à la racine du projet.\n",
        "Ici on ne va pas fixer les versions, on raffinera ce fichier ultérieurement.\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "\n",
        "## Application 7a: création du `requirements.txt`\n",
        "\n",
        "- Créer un fichier `requirements.txt` avec la liste des packages nécessaires\n",
        "- Ajouter une indication dans `README.md` sur l'installation des _packages_ grâce au fichier `requirements.txt`\n",
        ":::\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli7\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Tracer notre chaîne\n",
        "\n",
        "Quand votre projet passera en production, vous aurez un accès limité à celui-ci. Il est donc important de faire remonter, par le biais du _logging_ des informations critiques sur votre projet qui vous permettront de savoir où il en est (si vous avez accès à la console où il tourne) ou là où il s'est arrêté.\n",
        "\n",
        "L'utilisation de `print` montre rapidement ses limites pour cela. Les informations enregistrées ne persistent pas après la session et sont quelques peu rudimentaires.\n",
        "\n",
        "Pour faire du _logging_, la librairie consacrée depuis longtemps en `Python` est... [`logging`](https://docs.python.org/3/library/logging.html). On va néanmoins ici proposer d'utiliser [`loguru`](https://github.com/Delgan/loguru) qui est un peu plus simple à configurer (l'instanciation du _logger_ est plus aisée) et plus agréable grâce à ses messages en couleurs qui permettent de visuellement trier les informations.\n",
        "\n",
        "![](https://raw.githubusercontent.com/Delgan/loguru/master/docs/_static/img/demo.gif)\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "\n",
        "## Application 7b: remontée de messages par _logging_\n",
        "\n",
        "1. Installer `loguru` et l'ajouter au `requirements.txt`\n",
        "2. En s'aidant du `README` du projet sur [`Github`](https://github.com/Delgan/loguru), remplacer nos `print` par différents types de messages (info, success, etc.).\n",
        "3. Tester l'exécution du script en ligne de commande et observer vos sorties\n",
        "4. Mettre à jour le logger pour enregistrer dans un fichier de _log_. Ajouter celui-ci au `.gitignore` puis tester en ligne de commande votre script. Ouvrir le fichier en question, refaites tourner le script et regardez son évolutoin.\n",
        "5. Il est possible avec `loguru` de capturer les erreurs des fonctions grâce au système de cache décrit [ici](https://github.com/Delgan/loguru?tab=readme-ov-file#exceptions-catching-within-threads-or-main).\n",
        "Introduire une erreur dans une des fonctions (par exemple dans `split_train_test`) avec un code du type `raise ValueError(\"Problème ici\")`\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Étape 4 : stocker les données de manière externe {#stockageS3}\n",
        "\n",
        "L'étape précédente nous a permis d'isoler la configuration. Nous avons conceptuellement isolé les données du code lors des applications précédentes. Cependant, nous n'avons pas été au bout du chemin car le stockage des données reste conjoint à celui du code. Nous allons maintenant dissocier ces deux éléments.\n",
        "\n",
        "::: {.callout-warning collapse=\"true\"}\n",
        "## Pour en savoir plus sur le système de stockage `S3`\n",
        "\n",
        "Pour mettre en oeuvre cette étape, il peut être utile de\n",
        "comprendre un peu comme fonctionne le SSP Cloud.\n",
        "Vous devrez suivre la [documentation du SSP Cloud](https://inseefrlab.github.io/docs.sspcloud.fr/docs/fr/storage.html) pour la réaliser. Une aide-mémoire est également disponible dans le cours\n",
        "de 2e année de l'ENSAE [Python pour la _data science_](https://linogaliana-teaching.netlify.app/reads3/#).\n",
        ":::\n",
        "\n",
        "\n",
        "Le chapitre sur la [structure des projets](/chapters/projects-architecture.qmd)\n",
        "développe l'idée qu'il est recommandé de converger vers un modèle\n",
        "où environnements d'exécution, de stockage du code et des données sont conceptuellement\n",
        "séparés. Ce haut niveau d'exigence est un gain de temps important\n",
        "lors de la mise en production car au cours de cette dernière, le projet\n",
        "est amené à être exécuté sur une infrastructure informatique dédiée\n",
        "qu'il est bon d'anticiper. Schématiquement, nous visons la structure de projet suivante:\n",
        "\n",
        "![](https://inseefrlab.github.io/formation-bonnes-pratiques-git-R/slides/img/environment_clean.png)\n",
        "\n",
        "A l'heure actuelle, les données sont stockées dans le dépôt. C'est une\n",
        "mauvaise pratique. En premier lieu, `Git` n'est techniquement\n",
        "pas bien adapté au stockage de données. Ici ce n'est pas très grave\n",
        "car il ne s'agit pas de données volumineuses et ces dernières ne sont\n",
        "pas modifiées au cours de notre chaine de traitement.\n",
        "\n",
        "La raison principale\n",
        "est que les données traitées par les _data scientists_\n",
        "sont généralement soumises à des clauses de\n",
        "confidentialités ([RGPD](https://www.cnil.fr/fr/rgpd-de-quoi-parle-t-on), [secret statistique](https://www.insee.fr/fr/information/1300624)...). Mettre ces données sous contrôle de version\n",
        "c'est prendre le risque de les divulguer à un public non habilité.\n",
        "Il est donc recommandé de privilégier des outils techniques adaptés au\n",
        "stockage de données.\n",
        "\n",
        "L'idéal, dans notre cas, est d'utiliser une solution de stockage externe.\n",
        "On va utiliser pour cela `MinIO`, la solution de stockage de type `S3` offerte par le SSP Cloud.\n",
        "Cela nous permettra de supprimer les données de `Github` tout en maintenant la reproductibilité\n",
        "de notre projet [^history].\n",
        "\n",
        "[^history]: Attention, les données ont été _committées_ au moins une fois. Les supprimer\n",
        "du dépôt ne les efface pas de l'historique. Si cette erreur arrive, le mieux est de supprimer\n",
        "le dépôt en ligne, créer un nouvel historique `Git` et partir de celui-ci pour des publications\n",
        "ultérieures sur `Github`. Néanmoins l'idéal serait de ne pas s'exposer à cela. C'est justement\n",
        "l'objet des bonnes pratiques de ce cours: un `.gitignore` bien construit et une séparation des\n",
        "environnements de stockage du code et\n",
        "des données seront bien plus efficaces pour vous éviter ces problèmes que tout les conseils de\n",
        "vigilance que vous pourrez trouver ailleurs.\n",
        "\n",
        "Plus concrètement, nous allons adopter le pipeline suivant pour notre projet:\n",
        "\n",
        "![](/chapters/applications/figures/pipeline_appli8.png)\n",
        "\n",
        "Le scénario type est que nous avons une source brute, reçue sous forme de CSV, dont on ne peut changer le format. Il aurait été idéal d'avoir un format plus adapté au traitement de données pour ce fichier mais ce n'était pas de notre ressort. Notre chaine va aller chercher ce fichier, travailler dessus jusqu'à valoriser celui-ci sous la forme de notre matrice de confusion. Si on imagine que notre chaine prend un certain temps, il n'est pas inutile d'écrire des données intermédiaires. Pour faire cela, puisque nous avons la main, autant choisir un format adapté, à savoir le format `Parquet`.\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "\n",
        "## Application 8: utilisation d'un système de stockage distant\n",
        "\n",
        "A partir de la ligne de commande,\n",
        "utiliser l'utilitaire [MinIO](https://min.io/docs/minio/linux/reference/minio-mc.html)\n",
        "pour copier les données `data/raw/data.csv`\n",
        "vers votre\n",
        "bucket personnel. Les données intermédiaires\n",
        "peuvent être laissées en local mais doivent être ajoutées\n",
        "au `.gitignore`.\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>Indice</summary>\n",
        "\n",
        "Structure à adopter:\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "mc cp data/raw/data.csv s3/$BUCKET_PERSONNEL/ensae-reproductibilite/data/raw/data.csv\n",
        "```\n",
        "\n",
        "en modifiant `$BUCKET_PERSONNEL`, l'emplacement de votre bucket personnel\n",
        "</details>\n",
        "\n",
        "Pour se simplifier la vie, on va utiliser des URL de téléchargement des fichiers\n",
        "(comme si ceux-ci étaient sur n'importe quel espace de stockage) plutôt que d'utiliser\n",
        "une librairie `S3` compatible comme `boto3` ou `s3fs`.\n",
        "\n",
        "Par défaut, le contenu de votre _bucket_ est privé, seul vous y avez accès. Néanmoins,\n",
        "vous pouvez rendre accessible à tous en lecture le contenu de votre _bucket_ en\n",
        "faisant lui donnant des droits anonymes.\n",
        "Pour cela, en ligne de\n",
        "commande, faire:\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "mc anonymous set download s3/$BUCKET_PERSONNEL/ensae-reproductibilite/data/raw/\n",
        "```\n",
        "\n",
        "en modifiant `$BUCKET_PERSONNEL`. Les URL de téléchargement seront de la forme\n",
        "`https://minio.lab.sspcloud.fr/$BUCKET_PERSONNEL/ensae-reproductibilite/data/raw/data.csv`\n",
        "\n",
        "En premier lieu, on va améliorer la brique d'ingestion et de préparation des données\n",
        "\n",
        "- Modifier le fichier `.env` et la variable `data_path` pour utiliser, par défaut, directement l'URL dans l'import;\n",
        "- Modifier les valeurs par défaut dans votre code ;\n",
        "- Ajouter le dossier `data/` au `.gitignore` ainsi que les fichiers `*.parquet`\n",
        "- Supprimer le dossier `data` de votre projet et faites `git rm --cached -r data`\n",
        "\n",
        "\n",
        "Nous allons en profiter pour améliorer nos données intermédiaires. Dans `main.py`, remplacer les chemins par ceux-ci:\n",
        "\n",
        "```{.python file=\"main.py\"}\n",
        "# main.py\n",
        "data_path = os.environ.get(\"data_path\", URL_RAW)\n",
        "data_train_path = os.environ.get(\"train_path\", \"data/derived/train.parquet\")\n",
        "data_test_path = os.environ.get(\"test_path\", \"data/derived/test.parquet\")\n",
        "```\n",
        "\n",
        "où `URL_RAW` est le lien de la forme `\"https://minio.lab.sspcloud.fr/$BUCKET_PERSONNEL/ensae-reproductibilite/data/raw/data.csv\"`\n",
        "\n",
        "Dans `data/pipeline/build_pipeline.py`, remplacer l'écriture des données par ce morceau:\n",
        "\n",
        "```{.python file=\"data/pipeline/build_pipeline.py\"}\n",
        "# data/pipeline/build_pipeline.py\n",
        "if train_path:\n",
        "    pd.concat([X_train, y_train]).to_parquet(train_path)\n",
        "if test_path:\n",
        "    pd.concat([X_test, y_test]).to_parquet(test_path)\n",
        "```\n",
        "\n",
        "- Vérifier le bon fonctionnement de votre application.\n",
        "\n",
        "\n",
        "Maintenant qu'on a arrangé la structure de notre projet, c'est l'occasion\n",
        "de supprimer le code qui n'est plus nécessaire au bon fonctionnement de notre\n",
        "projet (cela réduit la charge de maintenance[^pourapres]).\n",
        "\n",
        "Pour vous aider, vous pouvez\n",
        "utiliser [`vulture`](https://pypi.org/project/vulture/) de manière itérative\n",
        "pour vous assister dans le nettoyage de votre code.\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "vulture main.py src/\n",
        "```\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "Exemple de sortie\n",
        "</summary>\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "vulture .\n",
        "```\n",
        "\n",
        "```{.python}\n",
        "src/data/import_data.py:3: unused function 'split_and_count' (60% confidence)\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        ":::\n",
        "\n",
        "[^pourapres]: Lorsqu'on développe du code qui finalement ne s'avère plus nécessaire, on a souvent un cas de conscience à le supprimer et on préfère le mettre de côté. Au final, ce syndrôme de Diogène est mauvais pour la pérennité du projet : on se retrouve à devoir maintenir une base de code qui n'est, en pratique, pas utilisée. Ce n'est pas un problème de supprimer un code ; si finalement celui-ci s'avère utile, on peut le retrouver grâce à l'historique `Git` et les outils de recherche sur `Github`. Le _package_ `vulture` est très pratique pour diagnostiquer les morceaux de code inutiles dans un projet.\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli8\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Partie 2bis: packagisation de son projet (optionnel)\n",
        "\n",
        "Cette série d'actions n'est pas forcément pertinente pour tous\n",
        "les projets. Elle fait un peu la transition entre la modularité\n",
        "et la portabilité.\n",
        "\n",
        "## Étape 1 : proposer des tests unitaires (optionnel)\n",
        "\n",
        "Notre code comporte un certain nombre de fonctions génériques.\n",
        "On peut vouloir tester leur usage sur des données standardisées,\n",
        "différentes de celles du Titanic.\n",
        "\n",
        "Même si la notion de tests unitaires\n",
        "prend plus de sens dans un _package_, nous pouvons proposer\n",
        "dans le projet des exemples d'utilisation de la fonction, ceci peut être pédagogique.\n",
        "\n",
        "Nous allons utiliser [`unittest`](https://docs.python.org/3/library/unittest.html)\n",
        "pour effectuer des tests unitaires. Cette approche nécessite quelques notions\n",
        "de programmation orientée objet ou une bonne discussion avec `ChatGPT`.\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "\n",
        "## Application 9: test unitaire _(optionnel)_\n",
        "\n",
        "Dans le dossier `tests/`, créer avec l'aide de `ChatGPT` ou \n",
        "de `Copilot` un test pour la fonction\n",
        "`split_and_count`. \n",
        "\n",
        "- Effectuer le test unitaire en ligne de commande avec `unittest` (`python -m unittest tests/test_split.py`). Corriger le test unitaire en cas d'erreur. \n",
        "- Si le temps le permet, proposer des variantes ou d'autres tests.\n",
        ":::\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli9\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-note}\n",
        "\n",
        "Lorsqu'on effectue des tests unitaires, on cherche généralement\n",
        "à tester le plus de lignes possibles de son code. On parle de\n",
        "__taux de couverture__ (_coverage rate_) pour désigner\n",
        "la statistique mesurant cela.\n",
        "\n",
        "Cela peut s'effectuer de la manière suivante avec le package\n",
        "[`coverage`](https://coverage.readthedocs.io/en/7.2.2/):\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "coverage run -m unittest tests/test_create_variable_title.py\n",
        "coverage report -m\n",
        "```\n",
        "\n",
        "```{.python}\n",
        "Name                                  Stmts   Miss  Cover   Missing\n",
        "-------------------------------------------------------------------\n",
        "src/features/build_features.py           34     21    38%   35-36, 48-58, 71-74, 85-89, 99-101, 111-113\n",
        "tests/test_create_variable_title.py      21      1    95%   54\n",
        "-------------------------------------------------------------------\n",
        "TOTAL                                    55     22    60%\n",
        "```\n",
        "\n",
        "Le taux de couverture est souvent mis en avant par les gros\n",
        "projets comme indicateur de leur qualité. Il existe d'ailleurs\n",
        "des badges `Github` dédiés.\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Étape 2 : transformer son projet en package (optionnel)\n",
        "\n",
        "Notre projet est modulaire, ce qui le rend assez simple à transformer\n",
        "en _package_, en s'inspirant de la structure du `cookiecutter` adapté, issu\n",
        "de [cet ouvrage](https://py-pkgs.org/03-how-to-package-a-python#package-structure).\n",
        "\n",
        "On va créer un _package_ nommé `titanicml` qui encapsule\n",
        "tout notre code et qui sera appelé\n",
        "par notre script `main.py`. La structure attendue\n",
        "est la suivante:\n",
        "\n",
        "<details>\n",
        "<summary>Structure visée</summary>\n",
        "\n",
        "```\n",
        "ensae-reproductibilite-application\n",
        "├── docs                                    ┐\n",
        "│   ├── main.py                             │\n",
        "│   └── notebooks                           │ Package documentation and examples\n",
        "│       └── titanic.ipynb                   │\n",
        "├── configuration                           ┐ Configuration (pas à partager avec Git)\n",
        "│   └── config.yaml                         ┘\n",
        "├── README.md\n",
        "├── pyproject.toml                          ┐\n",
        "├── requirements.txt                        │\n",
        "├── titanicml                               │\n",
        "│   ├── __init__.py                         │ Package source code, metadata\n",
        "│   ├── data                                │ and build instructions\n",
        "│   │   ├── import_data.py                  │\n",
        "│   │   └── test_create_variable_title.py   │\n",
        "│   ├── features                            │\n",
        "│   │   └── build_features.py               │\n",
        "│   └── models                              │\n",
        "│       └── train_evaluate.py               ┘\n",
        "└── tests                                   ┐\n",
        "    └── test_create_variable_title.py       ┘ Package tests\n",
        "```\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Rappel: structure actuelle</summary>\n",
        "\n",
        "```\n",
        "ensae-reproductibilite-application\n",
        "├── notebooks\n",
        "│   └── titanic.ipynb\n",
        "├── configuration\n",
        "│   └── config.yaml\n",
        "├── main.py\n",
        "├── README.md\n",
        "├── requirements.txt\n",
        "└── src\n",
        "    ├── data\n",
        "    │   ├── import_data.py\n",
        "    │   └── test_create_variable_title.py\n",
        "    ├── features\n",
        "    │   └── build_features.py\n",
        "    └── models\n",
        "        └── train_evaluate.py\n",
        "```\n",
        "</details>\n",
        "\n",
        "Il existe plusieurs\n",
        "_frameworks_ pour\n",
        "construire un _package_. Nous\n",
        "allons privilégier [`Poetry`](https://python-poetry.org/)\n",
        "à [`Setuptools`](https://pypi.org/project/setuptools/).\n",
        "\n",
        "\n",
        "::: {.callout-note}\n",
        "\n",
        "Pour créer la structure minimale d'un _package_, le plus simple est\n",
        "d'utiliser le `cookiecutter` adapté,\n",
        "issu de [cet ouvrage](https://py-pkgs.org/03-how-to-package-a-python#package-structure).\n",
        "\n",
        "Comme on a déjà une structure très modulaire, on va plutôt recréer cette\n",
        "structure dans notre projet déjà existant. En fait, il ne manque qu'un fichier essentiel,\n",
        "le principal distinguant un projet classique d'un package : `pyproject.toml`.\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "cookiecutter https://github.com/py-pkgs/py-pkgs-cookiecutter.git\n",
        "```\n",
        "\n",
        "<details>\n",
        "<summary>Dérouler pour voir les choix possibles</summary>\n",
        "```{.python}\n",
        "author_name [Monty Python]: Daffy Duck\n",
        "package_name [mypkg]: titanicml\n",
        "package_short_description []: Impressive Titanic survival analysis\n",
        "package_version [0.1.0]:\n",
        "python_version [3.9]:\n",
        "Select open_source_license:\n",
        "1 - MIT\n",
        "2 - Apache License 2.0\n",
        "3 - GNU General Public License v3.0\n",
        "4 - Creative Commons Attribution 4.0\n",
        "5 - BSD 3-Clause\n",
        "6 - Proprietary\n",
        "7 - None\n",
        "Choose from 1, 2, 3, 4, 5, 6 [1]:\n",
        "Select include_github_actions:\n",
        "1 - no\n",
        "2 - ci\n",
        "3 - ci+cd\n",
        "Choose from 1, 2, 3 [1]:\n",
        "```\n",
        "</details>\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "\n",
        "## Application 10: packagisation _(optionnel)_\n",
        "\n",
        "- Renommer le dossier `titanicml` pour respecter la nouvelle\n",
        "arborescence ;\n",
        "- Créer un fichier `pyproject.toml` sur cette base ;\n"
      ],
      "id": "3c793e60"
    },
    {
      "cell_type": "code",
      "metadata": {
        "filename": "pyproject.toml"
      },
      "source": [
        "#| eval: false\n",
        "#| code-summary: pyproject.toml\n",
        "[tool.poetry]\n",
        "name = \"titanicml\"\n",
        "version = \"0.0.1\"\n",
        "description = \"Awesome Machine Learning project\"\n",
        "authors = [\"Daffy Duck <daffy.duck@fauxmail.fr>\", \"Mickey Mouse\"]\n",
        "license = \"MIT\"\n",
        "readme = \"README.md\"\n",
        "\n",
        "[build-system]\n",
        "requires = [\"poetry-core\"]\n",
        "build-backend = \"poetry.core.masonry.api\"\n",
        "\n",
        "[tool.pytest.ini_options]\n",
        "log_cli = true\n",
        "log_cli_level = \"WARNING\"\n",
        "log_cli_format = \"%(asctime)s [%(levelname)8s] %(message)s (%(filename)s:%(lineno)s)\"\n",
        "log_cli_date_format = \"%Y-%m-%d %H:%M:%S\""
      ],
      "id": "9e423a34",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Créer le dossier `docs` et mettre les fichiers indiqués dedans\n",
        "- Dans `titanicml/`, créer un fichier `__init__.py`[^init]\n"
      ],
      "id": "705f10ab"
    },
    {
      "cell_type": "code",
      "metadata": {
        "filename": "__init__.py"
      },
      "source": [
        "#| eval: false\n",
        "#| code-summary: __init__.py\n",
        "from .data.import_data import (\n",
        "    split_and_count\n",
        ")\n",
        "from .pipeline.build_pipeline import (\n",
        "    split_train_test,\n",
        "    create_pipeline\n",
        ")\n",
        "from .models.train_evaluate import (\n",
        "    evaluate_model\n",
        ")\n",
        "__all__ = [\n",
        "    \"split_and_count\",\n",
        "    \"split_train_test\",\n",
        "    \"create_pipeline\",\n",
        "    \"evaluate_model\"\n",
        "]"
      ],
      "id": "7dd890cd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Installer le package en local avec `pip install -e .`\n",
        "- Modifier le contenu de `docs/main.py` pour importer les fonctions de notre _package_ `titanicml` et tester en\n",
        "ligne de commande notre fichier `main.py`\n",
        ":::\n",
        "\n",
        "[^init]: Le fichier `__init__.py` indique à `Python` que le dossier\n",
        "est un _package_. Il permet de proposer certaines configurations\n",
        "lors de l'import du _package_. Il permet également de contrôler\n",
        "les objets exportés (c'est-à-dire mis à disposition de l'utilisateur)\n",
        "par le _package_ par rapport aux objets internes au _package_.\n",
        "En le laissant vide, nous allons utiliser ce fichier\n",
        "pour importer l'ensemble des fonctions de nos sous-modules.\n",
        "Ce n'est pas la meilleure pratique mais un contrôle plus fin des\n",
        "objets exportés demanderait un investissement qui ne vaut, ici, pas\n",
        "le coût.\n",
        "\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli10\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "# Partie 3 : construction d'un projet portable et reproductible {#partie3}\n",
        "\n",
        "Dans la partie précédente,\n",
        "on a appliqué de manière incrémentale de nombreuses bonnes pratiques vues\n",
        "dans les chapitres [Qualité du code](/chapters/code-quality.html)\n",
        "et [Structure des projets](/chapters/projects-architecture.html)\n",
        "tout au long du cours.\n",
        "\n",
        "Ce faisant, on s'est déjà considérablement rapprochés d'une\n",
        "possible mise en production : le code est lisible,\n",
        "la structure du projet est normalisée et évolutive,\n",
        "et le code est proprement versionné sur un\n",
        "dépôt `GitHub` {{< fa brands github >}}.\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "Illustration de l'état actuel du projet\n",
        "</summary>\n",
        "![](/chapters/applications/figures/_pipeline_avant_partie3.png)\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "\n",
        "A présent, nous avons une version du projet qui est largement partageable.\n",
        "Du moins en théorie, car la pratique est souvent plus compliquée :\n",
        "il y a fort à parier que si vous essayez d'exécuter votre projet sur un autre environnement (typiquement, votre ordinateur personnel),\n",
        "les choses ne se passent pas du tout comme attendu. Cela signifie qu'**en l'état, le projet n'est pas portable : il n'est pas possible, sans modifications coûteuses, de l'exécuter dans un environnement différent de celui dans lequel il a été développé**.\n",
        "\n",
        "Dans cette troisème partie de notre travail vers la mise en production,\n",
        "nous allons voir\n",
        "comment **normaliser l'environnement d'exécution afin de produire un projet portable**.\n",
        "Autrement dit, nous n'allons plus nous contenter de modularité mais allons rechercher\n",
        "la portabilité.\n",
        "On sera alors tout proche de pouvoir mettre le projet en production.\n",
        "\n",
        "On progressera dans l'échelle de la reproductibilité\n",
        "de la manière suivante:\n",
        "\n",
        "1. [**Environnements virtuels**](#anaconda) ;\n",
        "2. Créer un [script shell](#shell) qui permet, depuis un environnement minimal, de construire l'application de A à Z ;\n",
        "3. [**Images et conteneurs `Docker`**](#docker).\n",
        "\n",
        "\n",
        "Nous allons repartir de l'application 8, c'est-à-dire d'un projet\n",
        "modulaire mais qui n'est pas, à strictement parler, un _package_\n",
        "(objet des applications optionnelles suivantes 9 et 10).\n",
        "\n",
        "Pour se replacer dans l'état du projet à ce niveau,\n",
        "il est possible d'utiliser le _tag_ _ad hoc_.\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash\n",
        "git checkout appli8\n",
        "```\n",
        "\n",
        "\n",
        "## Étape 1 : un environnement pour rendre le projet portable {#anaconda}\n",
        "\n",
        "Pour qu'un projet soit portable, il doit remplir deux conditions:\n",
        "\n",
        "- Ne pas nécessiter de dépendance\n",
        "qui ne soient pas renseignées quelque part ;\n",
        "- Ne pas proposer des dépendances inutiles, qui ne\n",
        "sont pas utilisées dans le cadre du projet.\n",
        "\n",
        "Le prochain exercice vise à mettre ceci en oeuvre.\n",
        "Comme expliqué dans le [chapitre portabilité](/chapters/portability.qmd),\n",
        "le choix du gestionnaire d'environnement est laissé\n",
        "libre. Il est recommandé de privilégier `venv` si vous découvrez\n",
        "la problématique de la portabilité.\n",
        "\n",
        "::: {.panel-tabset group=\"language\"}\n",
        "\n",
        "## Environnement virtuel `venv`\n",
        "\n",
        "L'approche la plus légère est l'environnement virtuel.\n",
        "Nous avons en fait implicitement déjà commencé à aller vers\n",
        "cette direction\n",
        "en créant un fichier `requirements.txt`.\n",
        "\n",
        "\n",
        ":::: {.callout-tip}\n",
        "\n",
        "## Application 11a: environnement virtuel `venv`\n",
        "\n",
        "1. Exécuter `pip freeze` en ligne de commande et observer la (très) longue\n",
        "liste de package\n",
        "2. Créer l'environnement virtuel `titanic` en s'inspirant de [la documentation officielle](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/)[^pythonversion] ou du [chapitre dédié](/chapters/portability.qmd)\n",
        "3. Utiliser `ls` pour observer et comprendre le contenu du dossier `titanic/bin` installé\n",
        "4. Activer l'environnement et vérifier l'installation de `Python` maintenant utilisée par votre machine\n",
        "<!---source titanic/bin/activate && which python---->\n",
        "5. Vérifier directement depuis la ligne de commande que `Python` exécute bien une commande[^option] avec:\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "python -c \"print('Hello')\"\n",
        "```\n",
        "\n",
        "6. Faire la même chose mais avec `import pandas as pd`\n",
        "7. Installer les _packages_ à partir du `requirements.txt`. Tester à nouveau `import pandas as pd` pour comprendre la différence.\n",
        "8. Exécuter `pip freeze` et comprendre la différence avec la situation précédente.\n",
        "9. Vérifier que le script `main.py` fonctionne bien. Sinon ajouter les _packages_ manquants dans le `requirements.txt` et reprendre de manière itérative à partir de la question 7.\n",
        "10. Ajouter le dossier `titanic/` au `.gitignore` pour ne pas ajouter ce dossier à `Git`.\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>Aide pour la question 4</summary>\n",
        "\n",
        "Après l'activation, vous pouvez vérifier quel `python`\n",
        "est utilisé de cette manière\n",
        "\n",
        "```{.bash filename=\"terminal\" env=\"titanic\"}\n",
        "which python\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "::::\n",
        "\n",
        "[^pythonversion]: Si vous désirez aussi contrôler la version de `Python`, ce qui peut être important\n",
        "dans une perspective de portabilité, vous pouvez ajouter une option, par exemple `-p python3.10`. Néanmoins\n",
        "nous n'allons pas nous embarasser de cette nuance pour la suite car nous pourrons contrôler\n",
        "la version de `Python` plus finement par le biais de `Docker`.\n",
        "[^option]: L'option `-c` passée après la commande `python` permet d'indiquer à `Python` que la commande\n",
        "ne se trouve pas dans un fichier mais sera dans le texte qu'on va directement lui fournir.\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli11a\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Environnement `conda`\n",
        "\n",
        "Les environnements `conda` sont plus lourds à mettre en oeuvre que les\n",
        "environnements virtuels mais peuvent permettre un contrôle\n",
        "plus formel des dépendances.\n",
        "\n",
        "\n",
        ":::: {.callout-tip}\n",
        "\n",
        "## Application 11b: environnement `conda` \n",
        "\n",
        "1. Exécuter `conda env export` en ligne de commande et observer la (très) longue\n",
        "liste de package\n",
        "2. Créer un environnement `titanic`\n",
        "avec [`conda create`](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-with-commands)\n",
        "4. Activer l'environnement et vérifier l'installation de `Python` maintenant utilisée par votre machine \n",
        "<!---conda activate titanic && which python---->\n",
        "5. Vérifier directement depuis la ligne de commande que `Python` exécute bien une commande[^option] avec:\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "python -c \"print('Hello')\"\n",
        "```\n",
        "\n",
        "6. Faire la même chose mais avec `import pandas as pd`\n",
        "7. Installer les _packages_ qu'on avait listé dans le `requirements.txt` précédemment. Ne pas faire un `pip install -r requirements.txt` afin de privilégier `conda install`\n",
        "8. Exécuter à nouveau `conda env export` et comprendre la différence avec la situation précédente[^splitscreen].\n",
        "9. Vérifier que le script `main.py` fonctionne bien. Sinon installer les _packages_ manquants\n",
        "et reprndre de manière itérative\n",
        "à partir de la question 7.\n",
        "10. Quand `main.py` fonctionne, faire `conda env export > environment.yml` pour figer l'environnement de travail.\n",
        "\n",
        "::::\n",
        "\n",
        "[^splitscreen]: Pour comparer les deux listes, vous pouvez utiliser la fonctionnalité de _split_ \n",
        "du terminal sur `VSCode` pour comparer les outputs de `conda env export` en les mettant \n",
        "en face à face. \n",
        "\n",
        ":::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli11b\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        "::::\n",
        "\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "## Étape 2: construire l'environnement de notre application via un script `shell` {#shell}\n",
        "\n",
        "Les environnements virtuels permettent de mieux spécifier les dépendances de notre projet, mais ne permettent pas de garantir une portabilité optimale. Pour cela, il faut recourir à la technologie des conteneurs. L'idée est de construire une machine, en partant d'une base quasi-vierge, qui permette de construire étape par étape l'environnement nécessaire au bon fonctionnement de notre projet. C'est le principe des conteneurs `Docker` {{< fa brands docker >}}.\n",
        "\n",
        "Leur méthode de construction étant un peu difficile à prendre en main au début, nous allons passer par une étape intermédiaire afin de bien comprendre le processus de production.\n",
        "\n",
        "- Nous allons d'abord créer un script `shell`, c'est à dire une suite de commandes `Linux` permettant de construire l'environnement à partir d'une machine vierge ;\n",
        "- Nous transformerons celui-ci en `Dockerfile` dans un deuxième temps. C'est l'objet de l'étape suivante.\n",
        "\n",
        "::: {.panel-tabset group=\"language\"}\n",
        "\n",
        "## Environnement virtuel `venv`\n",
        "\n",
        "\n",
        ":::: {.callout-tip}\n",
        "\n",
        "## Application 12a : créer un fichier d'installation de A à Z\n",
        "\n",
        "1. Créer un service `ubuntu` sur le SSP Cloud\n",
        "2. Ouvrir un terminal\n",
        "3. Cloner le dépôt \n",
        "4. Se placer dans le dossier du projet avec `cd`\n",
        "5. Se placer au niveau du checkpoint 11a avec `git checkout appli11a`\n",
        "6. Via l'explorateur de fichiers, créer le fichier `install.sh` à la racine du projet avec le contenu suivant:\n",
        "\n",
        "<details>\n",
        "<summary>Script à créer sous le nom `install.sh` </summary>\n",
        "```{.bash filename=\"install.sh\" no-prefix=true}\n",
        "#!/bin/bash\n",
        "\n",
        "# Install Python\n",
        "apt-get -y update\n",
        "apt-get install -y python3-pip python3-venv\n",
        "\n",
        "# Create empty virtual environment\n",
        "python3 -m venv titanic\n",
        "source titanic/bin/activate\n",
        "\n",
        "# Install project dependencies\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "</details>\n",
        "\n",
        "6. Changer les permissions sur le script pour le rendre exécutable\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "chmod +x install.sh\n",
        "```\n",
        "\n",
        "7. Exécuter le script depuis la ligne de commande avec des droits de super-utilisateur (nécessaires pour installer des *packages* via `apt`)\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "sudo ./install.sh\n",
        "```\n",
        "\n",
        "8. Vérifier que le script `main.py` fonctionne correctement dans l'environnement virtuel créé \n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "source titanic/bin/activate\n",
        "python3 main.py\n",
        "```\n",
        "\n",
        "::::\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli12a\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "## Environnement `conda`\n",
        "\n",
        "\n",
        ":::: {.callout-tip}\n",
        "\n",
        "## Application 12b : créer un fichier d'installation de A à Z\n",
        "\n",
        "1. Créer un service `ubuntu` sur le SSP Cloud\n",
        "2. Ouvrir un terminal\n",
        "3. Cloner le dépôt \n",
        "4. Se placer dans le dossier du projet avec `cd`\n",
        "5. Se placer au niveau du checkpoint 11b avec `git checkout appli11b`\n",
        "6. Via l'explorateur de fichiers, créer le fichier `install.sh` à la racine du projet avec le contenu suivant:\n",
        "\n",
        "<details>\n",
        "<summary>Script à créer sous le nom `install.sh` </summary>\n",
        "```{.bash filename=\"install.sh\" no-prefix=true}\n",
        "apt-get -y update && apt-get -y install wget\n",
        "\n",
        "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh && \\\n",
        "    bash Miniconda3-latest-Linux-x86_64.sh -b -p /miniconda && \\\n",
        "    rm -f Miniconda3-latest-Linux-x86_64.sh\n",
        "\n",
        "PATH=\"/miniconda/bin:${PATH}\"\n",
        "\n",
        "# Create environment\n",
        "conda create -n titanic pandas PyYAML scikit-learn -c conda-forge\n",
        "conda activate titanic\n",
        "\n",
        "PATH=\"/miniconda/envs/titanic/bin:${PATH}\"\n",
        "\n",
        "python main.py\n",
        "```\n",
        "</details>\n",
        "\n",
        "6. Changer les permissions sur le script pour le rendre exécutable\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "chmod +x install.sh\n",
        "```\n",
        "\n",
        "7. Exécuter le script depuis la ligne de commande avec des droits de super-utilisateur (nécessaires pour installer des *packages* via `apt`)\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "sudo ./install.sh\n",
        "```\n",
        "\n",
        "8. Vérifier que le script `main.py` fonctionne correctement dans l'environnement virtuel créé \n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "conda activate titanic\n",
        "python3 main.py\n",
        "```\n",
        "\n",
        "::::\n",
        "\n",
        ":::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli12b\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        "::::\n",
        "\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "## Étape 3: conteneuriser l'application avec `Docker` {#docker}\n",
        "\n",
        "\n",
        "::: {.callout-note}\n",
        "Cette application nécessite l'accès à une version interactive de `Docker`.\n",
        "Il n'y a pas beaucoup d'instances en ligne disponibles.\n",
        "\n",
        "Nous proposons deux solutions:\n",
        "\n",
        "- [Installer `Docker`](https://docs.docker.com/get-docker/) sur sa machine ;\n",
        "- Se rendre sur l'environnement bac à sable _[Play with Docker](https://labs.play-with-docker.com)_\n",
        "\n",
        "Sinon, elle peut être réalisée en essai-erreur par le biais des services d'intégration continue de `Github` {{< fa brands github >}} ou `Gitlab` {{< fa brands gitlab >}}. Néanmoins, nous présenterons l'utilisation de ces services plus tard, dans la prochaine partie.\n",
        ":::\n",
        "\n",
        "Maintenant qu'on sait que ce script préparatoire fonctionne, on va le transformer en `Dockerfile` pour anticiper la mise en production.  Comme la syntaxe `Docker` est légèrement différente de la syntaxe `Linux` classique (voir le [chapitre portabilité](/chapters/portability.qmd)), il va être nécessaire de changer quelques instructions mais ceci sera très léger.\n",
        "\n",
        "On va tester le `Dockerfile` dans un environnement bac à sable pour ensuite\n",
        "pouvoir plus facilement automatiser la construction de l'image\n",
        "`Docker`.\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "\n",
        "## Application 13: création de l'image `Docker` \n",
        "\n",
        "Se placer dans un environnement avec `Docker`, par\n",
        "exemple _[Play with Docker](https://labs.play-with-docker.com)_\n",
        "\n",
        "#### Création du `Dockerfile`\n",
        "\n",
        "- Dans le terminal `Linux`, cloner votre dépôt `Github` \n",
        "- Repartir de la dernière version à disposition. Par exemple, si vous avez privilégié \n",
        "l'environnement virtuel `venv`, ce sera:\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli12a\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "- Créer via la ligne de commande un fichier texte vierge nommé `Dockerfile` (la majuscule au début du mot est importante)\n",
        "\n",
        "<details><summary>Commande pour créer un `Dockerfile` vierge depuis la ligne de commande</summary>\n",
        "```{.bash filename=\"terminal\"}\n",
        "touch Dockerfile\n",
        "```\n",
        "</details>\n",
        "\n",
        "- Ouvrir ce fichier via un éditeur de texte et copier le contenu suivant dedans:\n",
        "\n",
        "<details><summary>Premier `Dockerfile`</summary>\n",
        "\n",
        "```{.bash filename=\"terminal\" no-prefix=true}\n",
        "FROM ubuntu:22.04\n",
        "\n",
        "WORKDIR ${HOME}/titanic\n",
        "\n",
        "# Install Python\n",
        "RUN apt-get -y update && \\\n",
        "    apt-get install -y python3-pip\n",
        "\n",
        "# Install project dependencies\n",
        "COPY requirements.txt .\n",
        "RUN pip install -r requirements.txt\n",
        "\n",
        "CMD [\"python3\", \"main.py\"]\n",
        "```\n",
        "</details>\n",
        "\n",
        "#### Construire (_build_) l'image\n",
        "\n",
        "- Utiliser `docker build` pour créer une image avec le tag `my-python-app`\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "docker build . -t my-python-app\n",
        "```\n",
        "\n",
        "- Vérifier les images dont vous disposez. Vous devriez avoir un résultat proche de celui-ci :\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "docker images\n",
        "```\n",
        "\n",
        "```{.python}\n",
        "REPOSITORY      TAG       IMAGE ID       CREATED              SIZE\n",
        "my-python-app   latest    188957e16594   About a minute ago   879MB\n",
        "```\n",
        "\n",
        "#### Tester l'image: découverte du cache\n",
        "\n",
        "L'étape de `build` a fonctionné: une image a été construite.\n",
        "\n",
        "Mais fait-elle effectivement ce que l'on attend d'elle ?\n",
        "\n",
        "Pour le savoir, il faut passer à l'étape suivante, l'étape de `run`.\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "docker run -it my-python-app\n",
        "```\n",
        "\n",
        "```{.python}\n",
        "python3: can't open file '/~/titanic/main.py': [Errno 2] No such file or directory\n",
        "```\n",
        "\n",
        "Le message d'erreur est clair : `Docker` ne sait pas où trouver le fichier `main.py`. D'ailleurs, il ne connait pas non plus les autres fichiers de notre application qui sont nécessaires pour faire tourner le code, par exemple le dossier `src`.\n",
        "\n",
        "- Avant l'étape `CMD`, copier les fichiers nécessaires sur l'image afin que l'application dispose de tous les éléments nécessaires pour être en mesure de fonctionner.\n",
        "\n",
        "<details>\n",
        "<summary>Nouveau `Dockerfile` </summary>\n",
        "```{.bash filename=\"terminal\" no-prefix=true}\n",
        "FROM ubuntu:22.04\n",
        "\n",
        "WORKDIR ${HOME}/titanic\n",
        "\n",
        "# Install Python\n",
        "RUN apt-get -y update && \\\n",
        "    apt-get install -y python3-pip\n",
        "\n",
        "# Install project dependencies\n",
        "COPY requirements.txt .\n",
        "RUN pip install -r requirements.txt\n",
        "\n",
        "COPY main.py .\n",
        "COPY src ./src\n",
        "CMD [\"python3\", \"main.py\"]\n",
        "```\n",
        "</details>\n",
        "\n",
        "- Refaire tourner l'étape de `build`\n",
        "\n",
        "- Refaire tourner l'étape de `run`. A ce stade, la matrice de confusion doit fonctionner 🎉.\n",
        "Vous avez créé votre première application reproductible !\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.callout-note}\n",
        "\n",
        "Ici, le _cache_ permet d'économiser beaucoup de temps. Par besoin de \n",
        "refaire tourner toutes les étapes, `Docker` agit de manière intelligente\n",
        "en faisant tourner uniquement les étapes qui ont changé.\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli13\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Partie 4 : automatisation avec l'intégration continue\n",
        "\n",
        "\n",
        "Imaginez que vous êtes au restaurant\n",
        "et qu'on ne vous serve pas le plat mais seulement la recette\n",
        "et que, de plus, on vous demande de préparer le plat\n",
        "chez vous avec les ingrédients dans votre frigo.\n",
        "Vous seriez quelque peu déçu. En revanche, si vous avez goûté\n",
        "au plat, que vous êtes un réel cordon bleu\n",
        "et qu'on vous donne la recette pour refaire ce plat ultérieurement,\n",
        "peut-être\n",
        "que vous appréciriez plus.\n",
        "\n",
        "Cette analogie illustre l'enjeu de définir\n",
        "le public cible et ses attentes afin de fournir un livrable adapté.\n",
        "Une image `Docker` est un livrable qui n'est pas forcément intéressant\n",
        "pour tous les publics. Certains préféreront avoir un plat bien préparé\n",
        "qu'une recette ; certains apprécieront avoir une image `Docker` mais\n",
        "d'autres ne seront pas en mesure de construire celle-ci ou ne sauront\n",
        "pas la faire fonctionner. Une image `Docker` est plus souvent un\n",
        "moyen pour faciliter la mise en service d'une production qu'une fin en soi.\n",
        "\n",
        "Nous allons donc proposer\n",
        "plusieurs types de livrables plus classiques par la suite. Ceux-ci\n",
        "correspondront mieux aux attendus des publics utilisateurs de services\n",
        "construits à partir de techniques de _data science_. `Docker` est néanmoins\n",
        "un passage obligé car l'ensemble des types de livrables que nous allons\n",
        "explorer reposent sur la standardisation permise par les conteneurs.\n",
        "\n",
        "Cette approche nous permettra de quitter le domaine de l'artisanat pour\n",
        "s'approcher d'une industrialisation de la mise à disposition\n",
        "de notre projet. Ceci va notamment nous amener à mettre en oeuvre\n",
        "l'approche pragmatique du `DevOps` qui consiste à intégrer dès la phase de\n",
        "développement d'un projet les contraintes liées à sa mise à disposition\n",
        "au public cible (cette approche est détaillée plus\n",
        "amplement dans le chapitre sur la [mise en production](/chapters/deployment.qmd)).\n",
        "\n",
        "L'automatisation et la mise à disposition automatisée de nos productions\n",
        "sera faite progressivement, au cours des prochaines parties. Tous les\n",
        "projets n'ont pas vocation à aller aussi loin dans ce domaine.\n",
        "L'opportunité doit être comparée aux coûts humains et financiers\n",
        "de leur mise en oeuvre et de leur cycle de vie.\n",
        "Avant de faire une production en série de nos modèles,\n",
        "nous allons déjà commencer\n",
        "par automatiser quelques tests de conformité de notre code.\n",
        "On va ici utiliser l'intégration continue pour deux objectifs distincts:\n",
        "\n",
        "- la mise à disposition de l'image `Docker` ;\n",
        "- la mise en place de tests automatisés de la qualité du code\n",
        "sur le modèle de notre `linter` précédent.\n",
        "\n",
        "Nous allons utiliser `Github Actions` pour cela. Il s'agit de serveurs\n",
        "standardisés mis à disposition gratuitement par `Github` {{<fa brands github >}}.\n",
        "`Gitlab` {{<fa brands gitlab >}}, l'autre principal acteur du domaine,\n",
        "propose des services similaires. L'implémentation est légèrement différente\n",
        "mais les principes sont identiques.\n",
        "\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Si vous prenez ce projet fil rouge en cours de route\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git checkout appli13\n",
        "```\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "## Étape 1: mise en place de tests automatisés\n",
        "\n",
        "Avant d'essayer de mettre en oeuvre la création de notre image\n",
        "`Docker` de manière automatisée, nous allons présenter la logique\n",
        "de l'intégration continue en testant de manière automatisée\n",
        "notre script `main.py`.\n",
        "\n",
        "Pour cela, nous allons partir de la structure proposée dans l'[action officielle](https://github.com/actions/setup-python).\n",
        "La documentation associée est [ici](https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python).\n",
        "Des éléments succincts de présentation de la logique déclarative des actions `Github`\n",
        "sont disponibles dans le chapitre sur la [mise en production](/chapters/deployment.qmd). Néanmoins, la meilleure\n",
        "école pour comprendre le fonctionnement de celles-ci est de parcourir la documentation du service et d'observer\n",
        "les actions `Github` mises en oeuvre par vos projets favoris, celles-ci seront fort instructives !\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "\n",
        "## Application 14: premier script d'intégration continue\n",
        "\n",
        "A partir de l'exemple présent\n",
        "dans la [documentation officielle](https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python#using-a-specific-python-version)\n",
        "de `Github` {{< fa brands github >}}, on a déjà une base de départ qui peut être modifiée.\n",
        "Les questions suivantes permettront d'automatiser les tests et le diagnostic qualité de\n",
        "notre code[^failure]\n",
        "\n",
        "[^failure]: Il est tout à fait normal de ne pas parvenir à créer une action fonctionnelle\n",
        "du premier coup. N'hésitez pas à _pusher_ votre code après chaque question pour vérifier\n",
        "que vous parvenez bien à réaliser chaque étape. Sinon vous risquez de devoir corriger\n",
        "bout par bout un fichier plus conséquent.\n",
        "\n",
        "1. Créer un fichier `.github/workflows/test.yaml` avec le contenu de l'exemple de la documentation\n",
        "3. Avec l'aide de la documentation, introduire une étape d'installation des dépendances.\n",
        "Utiliser le fichier `requirements.txt` pour installer les dépendances.\n",
        "4. Utiliser `pylint` pour vérifier la qualité du code. Ajouter l'argument `--fail-under=6` pour\n",
        "renvoyer une erreur en cas de note trop basse[^hook]\n",
        "5. Utiliser une étape appelant notre application en ligne de commande (`python main.py`)\n",
        "pour tester que la matrice de confusion s'affiche bien.\n",
        "6. Créer un secret stockant une valeur du `JETON_API`. Ne le faites pas commencer par un _\"$\"_ comme ça vous pourrez regarder la log ultérieurement\n",
        "7. Aller voir votre test automatisé dans l'onglet `Actions` de votre dépôt sur `Github`\n",
        "8. _(optionnel)_: Créer un _artefact_ à partir du fichier de _log_ que vous créez dans `main.py`\n",
        "\n",
        "[^hook]: Il existe une approche alternative pour faire des tests\n",
        "    réguliers: les _hooks_ `Git`.\n",
        "    Il s'agit de règles qui doivent être satisfaites pour que le\n",
        "    fichier puisse être committé. Cela assure que chaque `commit` remplisse\n",
        "    des critères de qualité afin d'éviter le problème de la procrastination.\n",
        "\n",
        "    La [documentation de pylint](https://pylint.pycqa.org/en/latest/user_guide/pre-commit-integration.html) offre des explications supplémentaires.\n",
        "    Ici, nous allons adopter une approche moins ambitieuse en demandant à notre\n",
        "    action de faire ce travail d'évaluation de la qualité de notre code\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli14\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Maintenant, nous pouvons observer que l'onglet `Actions`\n",
        "s'est enrichi. Chaque `commit` va entraîner une série d'actions automatisées.\n",
        "\n",
        "Si l'une des étapes échoue, ou si la note de notre projet est mauvaise, nous aurons\n",
        "une croix rouge (et nous recevrons un mail). On pourra ainsi détecter,\n",
        "en développant son projet, les moments où on dégrade la qualité du script\n",
        "afin de la rétablir immédiatemment.\n",
        "\n",
        "\n",
        "\n",
        "## Étape 2: Automatisation de la livraison de l'image `Docker`\n",
        "\n",
        "Maintenant, nous allons automatiser la mise à disposition de notre image\n",
        "sur `DockerHub` (le lieu de partage des images `Docker`). Cela facilitera sa réutilisation mais aussi des\n",
        "valorisations ultérieures.\n",
        "\n",
        "Là encore, nous allons utiliser une série d'actions pré-configurées.\n",
        "\n",
        "Pour que `Github` puisse s'authentifier auprès de `DockerHub`, il va\n",
        "falloir d'abord interfacer les deux plateformes. Pour cela, nous allons utiliser\n",
        "un jeton (_token_) `DockerHub` que nous allons mettre dans un espace\n",
        "sécurisé associé à votre dépôt `Github`.\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Application 15a: configuration\n",
        "\n",
        "- Se rendre sur\n",
        "[https://hub.docker.com/](https://hub.docker.com/) et créer un compte. Il est recommandé\n",
        "d'associer ce compte à votre compte `Github`.\n",
        "- Créer un dépôt public `application`\n",
        "- Aller dans les [paramètres de votre compte](https://hub.docker.com/settings/general)\n",
        "et cliquer, à gauche, sur `Security`\n",
        "- Créer un jeton personnel d'accès, ne fermez pas l'onglet en question,\n",
        "vous ne pouvez voir sa valeur qu'une fois.\n",
        "- Dans le dépôt `Github` de votre projet, cliquer sur l'onglet `Settings` et cliquer,\n",
        "à gauche, sur `Secrets and variables` puis\n",
        "dans le menu déroulant en dessous sur `Actions`. Sur la page qui s'affiche, aller\n",
        "dans la section `Repository secrets`\n",
        "- Créer un jeton `DOCKERHUB_TOKEN` à partir du jeton que vous aviez créé sur `Dockerhub`. Valider\n",
        "- Créer un deuxième secret nommé `DOCKERHUB_USERNAME` ayant comme valeur le nom d'utilisateur\n",
        "que vous avez créé sur `Dockerhub`\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "Etape optionnelle supplémentaire si on met en production un site web\n",
        "</summary>\n",
        "\n",
        "- Dans le dépôt `Github` de votre projet, cliquer sur l'onglet `Settings` et cliquer,\n",
        "à gauche, sur `Actions`. Donner les droits d'écriture à vos actions sur le dépôt\n",
        "du projet (ce sera nécessaire pour `Github Pages`)\n",
        "\n",
        "![](/permissions.png)\n",
        "\n",
        "</details>\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "A ce stade, nous avons donné les moyens à `Github` de s'authentifier avec\n",
        "notre identité sur `Dockerhub`. Il nous reste à mettre en oeuvre l'action\n",
        "en s'inspirant de la [documentation officielle](https://github.com/docker/build-push-action/#usage).\n",
        "On ne va modifier que trois éléments dans ce fichier. Effectuer les\n",
        "actions suivantes:\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "\n",
        "## Application 15b: automatisation de l'image `Docker`\n",
        "\n",
        "- En s'inspirant de ce [_template_](https://github.com/marketplace/actions/build-and-push-docker-images), créer le fichier `.github/workflows/prod.yml` qui va *build* et *push* l'image sur le `DockerHub`. Il va être nécessaire de changer légèrement ce modèle :\n",
        "    + Retirer la condition restrictive sur les _commits_ pour lesquels sont lancés cette automatisation. Pour cela, remplacer le contenu de `on` de sorte à avoir `on:\n",
        "  push:\n",
        "    branches:\n",
        "      - main\n",
        "      - dev`\n",
        "    + Changer le tag à la fin pour mettre `username/application:latest`\n",
        "où `username` est le nom d'utilisateur sur `DockerHub`;\n",
        "    + Optionnel: changer le nom de l'action\n",
        "\n",
        "- Faire un `commit` et un `push` de ces fichiers\n",
        "\n",
        "Comme on est fier de notre travail, on va afficher ça avec un badge sur le\n",
        "`README` _(partie optionnelle)_.\n",
        "\n",
        "- Se rendre dans l'onglet `Actions` et cliquer sur une des actions listées.\n",
        "- En haut à droite, cliquer sur `...`\n",
        "- Sélectionner `Create status badge`\n",
        "- Récupérer le code `Markdown` proposé\n",
        "- Copier dans votre `README.md` le code _markdown_ proposé\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "Créer le badge\n",
        "</summary>\n",
        "![](/create-badge.png)\n",
        "</details>\n",
        "\n",
        ":::\n",
        "\n",
        "Maintenant, il nous reste à tester notre application dans l'espace bac à sable\n",
        "ou en local, si `Docker` est installé.\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "\n",
        "## Application 15b (partie optionnelle): Tester l'application\n",
        "\n",
        "- Se rendre sur l'environnement bac à sable _[Play with Docker](https://labs.play-with-docker.com)_\n",
        "ou dans votre environnement `Docker` de prédilection.\n",
        "- Récupérer et lancer l'image :\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "docker run -it username/application:latest\n",
        "```\n",
        "\n",
        "🎉 La matrice de confusion doit s'afficher ! Vous avez grandement\n",
        "facilité la réutilisation de votre image.\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli15\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Partie 5: expérimenter en local des valorisations puis automatiser leur production\n",
        "\n",
        "\n",
        "Nous avons automatisé les étapes intermédiaires de notre projet.\n",
        "Néanmoins nous n'avons pas encore réfléchi à la valorisation\n",
        "à mettre en oeuvre pour notre projet. On va supposer que notre\n",
        "projet s'adresse à des _data scientists_ mais aussi à une audience\n",
        "moins technique. Pour ces premiers, nous pourrions nous contenter\n",
        "de valorisations techniques, comme des API,\n",
        "mais pour ces derniers il est\n",
        "conseillé de privilégier des formats plus _user friendly_.\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Si vous prenez ce projet fil rouge en cours de route\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git checkout appli15\n",
        "```\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "Afin de faire le parallèle avec les parcours possibles pour l'évaluation,\n",
        "nous allons proposer trois valorisations[^valorisation]:\n",
        "\n",
        "- Une [API](https://titanic.kub.sspcloud.fr/docs) facilitant la réutilisation du modèle en \"production\" ;\n",
        "- Un [site web statique](https://ensae-reproductibilite.github.io/application/) exploitant cette API pour exposer les prédictions\n",
        "à une audience moins technique.\n",
        "\n",
        "\n",
        "[^valorisation]: Vous n'êtes pas obligés pour l'évaluation de mettre en oeuvre\n",
        "les jalons de plusieurs parcours. Néanmoins, vous découvrirez que\n",
        "chaque nouveau pas en avant est moins coûteux que le\n",
        "précédent si vous avez mis en oeuvre les réflexes des bonnes\n",
        "pratiques.\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-warning collapse=\"true\"}\n",
        "## Site statique vs application réactive\n",
        "\n",
        "La solution que nous allons proposer\n",
        "pour les sites statiques, `Quarto` associé\n",
        "à `Github Pages`, peut être utilisée dans le cadre des parcours\n",
        "_\"rapport reproductible\"_ ou _\"dashboard / application interactive\"_.\n",
        "\n",
        "Pour ce dernier\n",
        "parcours, d'autres approches techniques sont néanmoins possibles,\n",
        "comme `Streamlit`. Celles-ci sont plus exigeantes sur le plan technique\n",
        "puisqu'elles nécessitent de mettre en production sur des serveurs\n",
        "conteuneurisés (comme la mise en production de l'API)\n",
        "là où le site statique ne nécessite qu'un serveur web, mis à disposition\n",
        "gratuitement par `Github`.\n",
        "\n",
        "\n",
        "La distinction principale entre ces deux approches est qu'elles\n",
        "s'appuient sur des serveurs différents. Un site statique repose\n",
        "sur un serveur web là où `Streamlit` s'appuie sur\n",
        "serveur classique en _backend_. La différence principale\n",
        "entre ces deux types de serveurs\n",
        "réside principalement dans leur fonction et leur utilisation:\n",
        "\n",
        "- Un __serveur web__ est spécifiquement conçu pour stocker, traiter et livrer des pages web aux clients. Cela inclut des fichiers HTML, CSS, JavaScript, images, etc. Les serveurs web écoutent les requêtes HTTP/HTTPS provenant des navigateurs des utilisateurs et y répondent en envoyant les données demandées.\n",
        "- Un **serveur _backend_** classique est conçu pour effectuer des opérations en réponse à un _front_, en l'occurrence une page web.\n",
        "Dans le contexte d'une application `Streamlit`, il s'agit d'un serveur avec l'environnement `Python` _ad hoc_ pour\n",
        "exécuter le code nécessaire à répondre à toute action d'un utilisateur de l'appliacation.\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "## Étape 1: développer une API en local\n",
        "\n",
        "Le premier livrable devenu classique dans un projet\n",
        "impliquant du _machine learning_ est la mise à\n",
        "disposition d'un modèle par le biais d'une\n",
        "API (voir chapitre sur la [mise en production](/chapters/deployment.qmd)).\n",
        "Le _framework_ [`FastAPI`](https://fastapi.tiangolo.com/) va permettre\n",
        "de rapidement transformer notre application `Python` en une API fonctionnelle.\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Si vous prenez ce projet fil rouge en cours de route\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git checkout appli15\n",
        "```\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "\n",
        "## Application 16: Mise à disposition sous forme d'API locale\n",
        "\n",
        "- Installer `fastAPI` et `uvicorn` puis les ajouter au `requirements.txt`\n",
        "- Renommer le fichier `main.py` en `train.py`. Dans ce script, ajouter une\n",
        "sauvegarde du modèle après l'avoir entraîné, sous le\n",
        "format [`joblib`](https://scikit-learn.org/stable/model_persistence.html#python-specific-serialization). \n",
        "- Faire tourner\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "python train.py\n",
        "```\n",
        "\n",
        "pour enregistrer en local votre modèle de production. \n",
        "\n",
        "- Modifier les appels à `main.py` dans votre `Dockerfile` et vos actions `Github`\n",
        "sous peine d'essuyer des échecs lors de vos actions `Github` après le prochain _push_. \n",
        "\n",
        "- Ajouter `model.joblib` au `.gitignore` car `Git` n'est pas fait pour \n",
        "ce type de fichiers. \n",
        "\n",
        "Nous allons maintenant passer au développement de l'API.\n",
        "Comme découvrir `FastAPI` n'est pas l'objet de cet enseignement, nous\n",
        "donnons directement le modèle pour créer l'API. Si vous\n",
        "désirez tester de vous-mêmes, vous pouvez créer votre \n",
        "fichier sans vous référer à l'exemple\n",
        "\n",
        "- Créer le fichier `api.py` permettant d'initialiser l'API:\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "Fichier `api.py`\n",
        "</summary>\n",
        "\n",
        "```{.python include=\"./applications/code/appli17_api_main.py\" filename=\"src/models/train_evaluation.py\"}\n",
        "```\n",
        "</details>\n",
        "\n",
        "- Déployer en local l'API avec la commande\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "uvicorn api:app --reload --host \"0.0.0.0\" --port 5000\n",
        "```\n",
        "\n",
        "- A partir du `README` du service, se rendre sur l'URL de déploiement, \n",
        "ajouter `/docs/` à celui-ci et observer la documentation de l'API \n",
        "- Se servir de la documentation pour tester les requêtes `/predict`\n",
        "- Récupérer l'URL d'une des requêtes proposées. La tester dans le navigateur\n",
        "et depuis `Python` avec `requests` :\n",
        "\n",
        "```{.python}\n",
        "import request\n",
        "requests.get(url).json()\n",
        "```\n",
        "\n",
        "- Une fois que vous avez testé, vous pouvez tuer l'application en faisant <kbd>CTRL</kbd>+<kbd>C</kbd>. Retester\n",
        "votre bout de code `Python` et comprendre l'origine du problème.\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli17\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Étape 2: déployer l'API de manière manuelle\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Si vous prenez ce projet fil rouge en cours de route\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git checkout appli16\n",
        "```\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "A ce stade, nous avons déployé l'API seulement localement, dans le cadre d'un terminal qui tourne en arrière-plan.\n",
        "C'est une mise en production manuelle, pas franchement pérenne.\n",
        "Ce mode de déploiement est très pratique pour la phase de développement, afin de s'assurer que l'API fonctionne comme attendu.\n",
        "Pour pérenniser la mise en production, on va éliminer l'aspect artisanal de celle-ci.\n",
        "\n",
        "Il est temps de passer à l'étape de déploiement, qui permettra à notre API d'être accessible via une URL sur le web\n",
        "et d'avoir un serveur, en arrière plan, qui effectuera les opérations pour répondre à une\n",
        "requête. Pour se faire, on va utiliser les possibilités offertes par `Kubernetes`, sur lequel est basé le [SSP Cloud](https://datalab.sspcloud.fr).\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Application 17: Dockeriser l'API (intégration continue)\n",
        "\n",
        "- Pour rendre la structure du projet plus lisible, déplacer `api.py` -> `api/main.py`\n",
        "\n",
        "- Créer un script `api/run.sh` à la racine du projet qui lance le script `train.py` puis déploie localement l'API\n",
        "\n",
        "<details>\n",
        "<summary>Fichier `run.sh`</summary>\n",
        "\n",
        "```{.bash filename=\"api/run.sh\" no-prefix=true}\n",
        "#/bin/bash\n",
        "\n",
        "python3 train.py\n",
        "uvicorn api.main:app --reload --host \"0.0.0.0\" --port 5000\n",
        "```\n",
        "</details>\n",
        "\n",
        "- Donner au script `api/run.sh` des permissions d'exécution : `chmod +x api/run.sh`\n",
        "\n",
        "- Ajouter `COPY api ./api` pour avoir les fichiers nécessaires au lancement dans l'API dans l'image\n",
        "\n",
        "- Modifier `COPY train.py .` pour tenir compte du nouveau nom du fichier\n",
        "\n",
        "- Changer l'instruction `CMD` du `Dockerfile` pour exécuter le script `api/run.sh` au lancement du conteneur (`CMD [\"bash\", \"-c\", \"./api/run.sh\"]`)\n",
        "\n",
        "- Mettre à jour votre `requirements.txt` pour tenir compte des nouveaux _packages_ utilisés\n",
        "\n",
        "- *Commit* et *push* les changements\n",
        "\n",
        "- Une fois le CI terminé, récupérer la nouvelle image dans votre environnement de test de `Docker` et vérifier que l'API se déploie correctement\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Nous avons préparé la mise à disposition de notre API mais à l'heure\n",
        "actuelle elle n'est pas disponible de manière aisée car il est nécessaire\n",
        "de lancer manuellement une image `Docker` pour pouvoir y accéder.\n",
        "Ce type de travail est la spécialité de `Kubernetes` que nous allons\n",
        "utiliser pour gérer la mise à disposition de notre API.\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Application 18b: Mettre à disposition l'API (déploiement manuel)\n",
        "\n",
        "Cette partie nécessite d'avoir à disposition une infrastructure _cloud_.\n",
        "\n",
        "- Créer un dossier `deployment` à la racine du projet qui va contenir les fichiers de configuration nécessaires pour déployer sur un cluster `Kubernetes`\n",
        "\n",
        "- En vous inspirant de la [documentation](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#creating-a-deployment), y ajouter un premier fichier `deployment.yaml` qui va spécifier la configuration du *Pod* à lancer sur le cluster\n",
        "\n",
        "<details>\n",
        "<summary>Fichier `deployment/deployment.yaml`</summary>\n"
      ],
      "id": "91ad9a82"
    },
    {
      "cell_type": "code",
      "metadata": {
        "filename": "deployment/deployment.yaml",
        "source-line-numbers": "19"
      },
      "source": [
        "#| eval: false\n",
        "apiVersion: apps/v1\n",
        "kind: Deployment\n",
        "metadata:\n",
        "  name: titanic-deployment\n",
        "  labels:\n",
        "    app: titanic\n",
        "spec:\n",
        "  replicas: 1\n",
        "  selector:\n",
        "    matchLabels:\n",
        "      app: titanic\n",
        "  template:\n",
        "    metadata:\n",
        "      labels:\n",
        "        app: titanic\n",
        "    spec:\n",
        "      containers:\n",
        "      - name: titanic\n",
        "        image: #<1>\n",
        "        ports:\n",
        "        - containerPort: 5000"
      ],
      "id": "ee2e723b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Mettre ici l'image `Docker` utilisée, sous la forme `username/image:latest`\n",
        "\n",
        "</details>\n",
        "\n",
        "- En vous inspirant de la [documentation](https://kubernetes.io/fr/docs/concepts/services-networking/service/#d%C3%A9finition-d-un-service), y ajouter un second fichier `service.yaml` qui va créer une ressource `Service` permettant de donner une identité fixe au `Pod` précédemment créé au sein du cluster\n",
        "\n",
        "<details>\n",
        "<summary>Fichier `deployment/service.yaml`</summary>\n",
        "\n",
        "```{.yaml filename=\"deployment/service.yaml\"}\n",
        "apiVersion: v1\n",
        "kind: Service\n",
        "metadata:\n",
        "  name: titanic-service\n",
        "spec:\n",
        "  selector:\n",
        "    app: titanic\n",
        "  ports:\n",
        "    - protocol: TCP\n",
        "      port: 80\n",
        "      targetPort: 5000\n",
        "```\n",
        "</details>\n",
        "\n",
        "- En vous inspirant de la [documentation](https://kubernetes.io/docs/concepts/services-networking/ingress/#the-ingress-resource), y ajouter un troisième fichier `ingress.yaml` qui va créer une ressource `Ingress` permettant d'exposer le service via une URL en dehors du cluster\n",
        "\n",
        "<details>\n",
        "<summary>Fichier `deployment/ingress.yaml`</summary>\n"
      ],
      "id": "e4c46464"
    },
    {
      "cell_type": "code",
      "metadata": {
        "filename": "deployment/ingress.yaml",
        "source-line-numbers": "16-19"
      },
      "source": [
        "#| eval: false\n",
        "apiVersion: networking.k8s.io/v1\n",
        "kind: Ingress\n",
        "metadata:\n",
        "  name: titanic-ingress\n",
        "  annotations:\n",
        "    nginx.ingress.kubernetes.io/rewrite-target: /\n",
        "    # Enable CORS by adding these annotations\n",
        "    nginx.ingress.kubernetes.io/enable-cors: \"true\"\n",
        "    nginx.ingress.kubernetes.io/cors-allow-methods: \"PUT, GET, POST, DELETE, PATCH, OPTIONS\"\n",
        "    nginx.ingress.kubernetes.io/cors-allow-credentials: \"true\"\n",
        "    nginx.ingress.kubernetes.io/cors-allow-headers: \"DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization\"\n",
        "    nginx.ingress.kubernetes.io/cors-allow-origin: \"*\"\n",
        "spec:\n",
        "  ingressClassName: nginx\n",
        "  tls:\n",
        "  - hosts:\n",
        "    - #<1>\n",
        "  rules:\n",
        "  - host: #<2>\n",
        "    http:\n",
        "      paths:\n",
        "      - path: /\n",
        "        pathType: Prefix\n",
        "        backend:\n",
        "          service:\n",
        "            name: titanic-service\n",
        "            port:\n",
        "              number: 80"
      ],
      "id": "c25c1e73",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Mettez l'URL auquel vous voulez exposer votre service. Sur le modèle de `titanic.kub.sspcloud.fr` (mais ne tentez pas celui-là, il est déjà pris 😃)\n",
        "2. Mettre ce même URL ici aussi\n",
        "</details>\n",
        "\n",
        "- Appliquer ces fichiers de configuration sur le cluster : `kubectl apply -f deployment/`\n",
        "\n",
        "- Si tout a correctement fonctionné, vous devriez pouvoir accéder depuis votre navigateur à l'API à l'URL spécifiée dans le fichier `deployment/ingress.yaml`. Par exemple `https://toto.kub.sspcloud.fr/` si vous avez mis celui-ci plus tôt (et `https://toto.kub.sspcloud.fr/docs` pour la documentation).\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli18\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-note title=\"Gérer le CORS\" collapse=\"true\"}\n",
        "Notre API est accessible sans problème depuis `Python` ou notre navigateur.\n",
        "\n",
        "En revanche, si on désire utiliser `JavaScript` pour créer une application\n",
        "interactive il est indispensable de mettre\n",
        "les lignes un peu obscure sur le CORS dans le fichier `ingress.yaml`.\n",
        "\n",
        "Comme c'est un point technique qui ne concerne pas les compétences\n",
        "liées à ce cours, nous donnons directement les mises à jour nécessaires\n",
        "du projet.\n",
        "\n",
        "Ceci consiste principalement à ajouter la ligne suivante au fichier `ingress.yaml` :\n",
        "\n",
        "```\n",
        "nginx.ingress.kubernetes.io/enable-cors: \"true\"\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "On peut remarquer quelques voies d'amélioration de notre approche qui\n",
        "seront ultérieurement traitées:\n",
        "\n",
        "- L'entraînement du modèle\n",
        "est ré-effectué à chaque lancement d'un nouveau conteneur.\n",
        "On relance donc autant de fois un entraînement qu'on déploie\n",
        "de conteneurs pour répondre à nos utilisateurs. Ce sera\n",
        "l'objet de la partie MLOps de fiabiliser et optimiser\n",
        "cette partie du _pipeline_.\n",
        "- il est nécessaire de (re)lancer manuellement  `kubectl apply -f deployment/`\n",
        "à chaque changement de notre code. Autrement dit, lors de cette application,\n",
        "on a amélioré\n",
        "la fiabilité du lancement de notre API mais un lancement manuel est encore indispensable.\n",
        "Comme dans le reste de ce cours, on va essayer d'éviter un geste manuel pouvant\n",
        "être source d'erreur en privilégiant l'automatisation et l'archivage dans des\n",
        "scripts. C'est l'objet de la prochaine étape.\n",
        "\n",
        "\n",
        "## Etape 3: automatiser le déploiement (déploiement en continu)\n",
        "\n",
        "::: {.callout-important}\n",
        "## Clarification sur la branche de travail et les _tags_\n",
        "\n",
        "A partir de maintenant, il est nécessaire de clarifier la\n",
        "branche principale sur laquelle nous travaillons. De manière\n",
        "traditionnelle, on utilise la branche `main`. Si vous avez changé de branche,\n",
        "vous pouvez continuer 1/ continuer mais en tenir compte dans les exemples ultérieurs ou 2/ fusionner celle-ci à `main`.\n",
        "\n",
        "Si vous avez utilisé un `tag` pour sauter une ou plusieurs étapes, il va\n",
        "être nécessaire de se placer sur une branche car vous êtes en _head detached_.\n",
        "Pour cela, après avoir _committé_ les fichiers que vous désirez garder\n"
      ],
      "id": "824b26be"
    },
    {
      "cell_type": "code",
      "metadata": {
        "file": "terminal",
        "filename": "terminal"
      },
      "source": [
        "#| eval: false\n",
        "$ git branch -D dev #<1>\n",
        "$ git push origin -d dev #<2>\n",
        "$ git checkout -b dev #<3>\n",
        "$ git push --set-upstream origin dev #<4>"
      ],
      "id": "7f83d02c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Supprime la branche `dev` *locale* (si elle existe).\n",
        "2. Supprime la branche `dev` *remote* (si elle existe).\n",
        "3. Crée une nouvelle branche `dev` *locale* et on se place sur cette branche.\n",
        "4. Pousse la branche `dev` et active la synchronisation entre la branche *locale* et la branche *remote*.\n",
        ":::\n",
        "\n",
        "Qu'est-ce qui peut déclencher une évolution nécessitant de mettre à jour l'ensemble de notre processus de production ?\n",
        "\n",
        "Regardons à nouveau notre _pipeline_:\n",
        "\n",
        "![](/drawio/end_point.png)\n",
        "\n",
        "Les _inputs_ de notre _pipeline_ sont donc:\n",
        "\n",
        "- La __configuration__. Ici, on peut considérer que notre `.env` de configuration ou les secrets renseignés à `Github` relèvent de cette catégorie  ;\n",
        "- Les __données__. Nos données sont statiques et n'ont pas vocation à évoluer. Si c'était le cas, il faudrait en tenir compte dans notre automatisation[^versionning-data]. ;\n",
        "- Le __code__. C'est l'élément principal qui évolue chez nous. Idéalement, on veut automatiser le processus au maximum en faisant en sorte qu'à chaque mise à jour de notre code (un _push_ sur `Github`), les étapes ultérieures (production de l'image `Docker`, etc.) se lancent. Néanmoins, on veut aussi éviter qu'une erreur puisse donner lieu à une mise en production non-fonctionnelle, on va donc maintenir une action manuelle minimale comme garde-fou.\n",
        "\n",
        "::: {.callout-note}\n",
        "## Et le _versionning_ des données ?\n",
        "\n",
        "Ici, nous nous plaçons dans le cas simple où les données brutes reçues sont figées. Ce qui peut changer est la manière dont on constitue nos échantillons train/test. Il sera donc utile de logguer les données en question par le biais de `MLFlow`. Mais il n'est pas nécessaire de versionner les données brutes.\n",
        "\n",
        "Si celles-ci évoluaient, il pourrait être utile de versionner les données, à la manière dont on le fait pour le code. `Git` n'est pas l'outil approprié pour cela. Parmi les outils populaires de versionning de données, bien intégrés avec S3, il y a sur le SSPCloud [`lakefs`](https://lakefs.io/).\n",
        ":::\n",
        "\n",
        "Pour automatiser au maximum la mise en production, on va utiliser un nouvel outil : `ArgoCD`. Ainsi, au lieu de devoir appliquer manuellement la commande `kubectl apply` à chaque modification des fichiers de déploiement (présents dans le dossier `kubernetes/`), c'est l'**opérateur** `ArgoCD`, déployé sur le cluster, qui va détecter les changements de configuration du déploiement et les appliquer automatiquement.\n",
        "\n",
        "C'est l'approche dite **GitOps** : le dépôt `Git` du déploiement fait office de **source de vérité unique** de l'état voulu de l'application, tout changement sur ce dernier doit donc se répercuter immédiatement sur le déploiement effectif.\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Application 19a: Automatiser la mise à disposition de l'API (déploiement continu)\n",
        "\n",
        "- Lancer un service `ArgoCD` sur le `SSPCloud` depuis la page `Mes services` (catalogue `Automation`). Laisser\n",
        "les configurations par défaut.\n",
        "- Sur `GitHub`, créer un dépôt `application-deployment` qui va servir de **dépôt GitOps**, c'est à dire un dépôt qui spécifie le paramétrage du déploiement de votre application.\n",
        "- Ajouter un dossier `deployment` à votre dépôt `GitOps`, dans lequel on mettra les trois fichiers de déploiement qui permettent de déployer notre application sur `Kubernetes` (`deployment.yaml`, `service.yaml`, `ingress.yaml`).\n",
        "- A la racine de votre dépôt `GitOps`, créez un fichier `application.yml` avec le contenu suivant, en prenant bien soin de modifier les lignes surlignées avec les informations pertinentes :\n"
      ],
      "id": "1df5331e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "file": "application.yaml",
        "filename": "application.yaml",
        "source-line-numbers": "8-9,13"
      },
      "source": [
        "#| eval: false\n",
        "apiVersion: argoproj.io/v1alpha1\n",
        "kind: Application\n",
        "metadata:\n",
        "  name: ensae-mlops\n",
        "spec:\n",
        "  project: default\n",
        "  source:\n",
        "    repoURL: https://github.com/<your_github_username>/application-deployment.git #<1>\n",
        "    targetRevision: main #<2>\n",
        "    path: deployment #<3>\n",
        "  destination:\n",
        "    server: https://kubernetes.default.svc\n",
        "    namespace: user-<your_sspcloud_username> #<4>\n",
        "  syncPolicy:\n",
        "    automated:\n",
        "      selfHeal: true"
      ],
      "id": "a7389ff6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. L'URL de votre dépôt `Github` {{< fa brands github >}} faisant office de dépôt `GitOps`.\n",
        "2. La branche à partir de laquelle vous déployez.\n",
        "3. Le nom du dossier contenant vos fichiers de déploiement `Kubernetes`.\n",
        "4. Votre _namespace_ `Kubernetes`. Sur le SSPCloud, cela prend la forme `user-${username}`.\n",
        "\n",
        "- Pousser sur `Github` le dépôt `GitOps`.\n",
        "- Dans `ArgoCD`, cliquez sur `New App` puis `Edit as a YAML`. Copiez-collez le contenu de `application.yml` et cliquez sur `Create`.\n",
        "- Observez dans l'interface d'`ArgoCD` le déploiement progressif des ressources nécessaires à votre application sur le cluster. Joli non ?\n",
        "- Vérifiez que votre API est bien déployée en utilisant l’URL définie dans le fichier `ingress.yml`.\n",
        "- Supprimer du code applicatif le dossier `deployment` puisque c'est maintenant votre dépôt de déploiement qui le contrôle.\n",
        "- Indiquer dans le `README.md` que le déploiement de votre application (dont vous pouvez mettre l'URL dans le README) est contrôlé par un autre dépôt.\n",
        "\n",
        ":::\n",
        "\n",
        "Si cela a fonctionné, vous devriez maintenant voir votre application dans votre tableau de bord `ArgoCD`:\n",
        "\n",
        "![](/chapters/applications/figures/argo_appli19a.png)\n",
        "\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli19a\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "A présent, nous avons tous les outils à notre disposition pour construire un vrai **pipeline de CI/CD, automatisé de bout en bout**. Il va nous suffire pour cela de mettre à bout les composants :\n",
        "\n",
        "- dans la partie 4 de l'application, nous avons construit un **pipeline de CI** : on a donc seulement à faire un commit sur le dépôt de l'application pour lancer l'étape de **build** et de mise à disposition de la nouvelle image sur le `DockerHub` ;\n",
        "\n",
        "- dans l'application précédente, nous avons construit un **pipeline de CD** : `ArgoCD` suit en permanence l'état du dépôt `GitOps`, tout commit sur ce dernier lancera donc automatiquement un redéploiement de l'application.\n",
        "\n",
        "Il y a donc un élément qui fait la liaison entre ces deux pipelines et qui nous sert de garde-fou en cas d'erreur : la **version de l'application**.\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Application 19b : Mettre à jour la version en production\n",
        "\n",
        "Jusqu'à maintenant, on a utilisé le tag *latest* pour définir la version de notre application. En pratique, lorsqu'on passe de la phase de développement à celle de production, on a plutôt envie de versionner proprement les versions de l'application afin de savoir ce qui est déployé. On va pour cela utiliser les ***tags*** avec `Git`, qui vont se propager au nommage de l'image `Docker`.\n",
        "\n",
        "- Modifier le fichier de CI `prod.yml` pour assurer la propagation des tags.\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "\n",
        "Fichier `.github/workflows/prod.yml`\n",
        "\n",
        "</summary>\n",
        "\n",
        "```{.yaml filename=\".github/workflows/prod.yml\"}\n",
        "name: Construction image Docker\n",
        "\n",
        "on:\n",
        "  push:\n",
        "    branches:\n",
        "      - main\n",
        "      - dev\n",
        "    tags:\n",
        "      - 'v*.*.*'\n",
        "\n",
        "jobs:\n",
        "  docker:\n",
        "    runs-on: ubuntu-latest\n",
        "    steps:\n",
        "      -\n",
        "        name: Set up QEMU\n",
        "        uses: docker/setup-qemu-action@v3\n",
        "      -\n",
        "        name: Set up Docker Buildx\n",
        "        uses: docker/setup-buildx-action@v3\n",
        "\n",
        "      -\n",
        "        name: Docker meta\n",
        "        id: meta\n",
        "        uses: docker/metadata-action@v5\n",
        "        with:\n",
        "          images: linogaliana/application #<1>\n",
        "\n",
        "      -\n",
        "        name: Login to Docker Hub\n",
        "        uses: docker/login-action@v3\n",
        "        with:\n",
        "          username: ${{ secrets.DOCKERHUB_USERNAME }}\n",
        "          password: ${{ secrets.DOCKERHUB_TOKEN }}\n",
        "      -\n",
        "        name: Build and push\n",
        "        uses: docker/build-push-action@v5\n",
        "        with:\n",
        "          push: true\n",
        "          tags: ${{ steps.meta.outputs.tags }}\n",
        "          labels: ${{ steps.meta.outputs.labels }}\n",
        "```\n",
        "1. Modifier ici !\n",
        "\n",
        "</details>\n",
        "\n",
        "- Dans le dépôt de l'application, mettre à jour le code dans `api/main.py` pour changer un élément de l'interface de votre documentation.\n",
        "Par exemple, mettre en gras un titre.\n",
        "\n",
        "```{.python}\n",
        "app = FastAPI(\n",
        "    title=\"Démonstration du modèle de prédiction de survie sur le Titanic\",\n",
        "    description=\n",
        "    \"<b>Application de prédiction de survie sur le Titanic</b> 🚢 <br>Une version par API pour faciliter la réutilisation du modèle 🚀\" +\\\n",
        "        \"<br><br><img src=\\\"https://media.vogue.fr/photos/5faac06d39c5194ff9752ec9/1:1/w_2404,h_2404,c_limit/076_CHL_126884.jpg\\\" width=\\\"200\\\">\"\n",
        "    )\n",
        "```\n",
        "\n",
        "- *Commit* et *push* les changements.\n",
        "\n",
        "- Tagger le commit effectué précédemment et *push* le nouveau tag :\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git tag v0.0.1\n",
        "git push --tags\n",
        "```\n",
        "\n",
        "- Vérifier sur le dépôt `GitHub` de l'application que ce *commit* lance bien un pipeline de CI **associé au tag v1.0.0**. Une fois terminé, vérifier sur le `DockerHub` que le tag `v0.0.1` existe bien parmi les tags disponibles de l'image.\n",
        "\n",
        "La partie CI a correctement fonctionné. Intéressons-nous à présent à la partie CD.\n",
        "\n",
        "- Sur le dépôt `GitOps`, mettre à jour la version de l'image à déployer en production dans le fichier `deployment/deployment.yaml`\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "\n",
        "Fichier `deployment/deployment.yaml`\n",
        "\n",
        "</summary>\n"
      ],
      "id": "91a66f5e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "file": "deployment/deployment.yaml",
        "filename": "deployment/deployment.yaml",
        "source-line-numbers": "19"
      },
      "source": [
        "#| eval: false\n",
        "apiVersion: apps/v1\n",
        "kind: Deployment\n",
        "metadata:\n",
        "  name: titanic-deployment\n",
        "  labels:\n",
        "    app: titanic\n",
        "spec:\n",
        "  replicas: 1\n",
        "  selector:\n",
        "    matchLabels:\n",
        "      app: titanic\n",
        "  template:\n",
        "    metadata:\n",
        "      labels:\n",
        "        app: titanic\n",
        "    spec:\n",
        "      containers:\n",
        "      - name: titanic\n",
        "        image: linogaliana/application:v0.0.1 #<1>\n",
        "        ports:\n",
        "        - containerPort: 5000"
      ],
      "id": "2b02f75c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Remplacer ici par le dépôt applicatif adéquat\n",
        "\n",
        "\n",
        "</details>\n",
        "\n",
        "- Après avoir _committé_ et _pushé_, observer dans `ArgoCD` le statut de votre application. Normalement, l'opérateur devrait avoir automatiquement identifié le changement, et mettre à jour le déploiement pour en tenir compte.\n",
        "\n",
        "![](/argocd-waiting.png)\n",
        "\n",
        "- Vérifier que l'API a bien été mise à jour.\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli19b\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Etape 4: construire un site web\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Si vous prenez ce projet fil rouge en cours de route\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git checkout appli19\n",
        "git checkout -b dev\n",
        "git push origin dev\n",
        "```\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "On va proposer un nouveau livrable pour parler à un public plus large.\n",
        "Pour faire ce site web,\n",
        "on va utiliser `Quarto` et déployer sur `Github Pages`.\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "\n",
        "## Application 20: Création d'un site web pour valoriser le projet\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "quarto create project website mysite\n",
        "```\n",
        "\n",
        "- Faire remonter d'un niveau `_quarto.yml`\n",
        "- Supprimer `about.qmd`, déplacer `index.qmd` vers la racine de notre projet.\n",
        "- Remplacer le contenu de `index.qmd` par [celui-ci](https://raw.githubusercontent.com/ensae-reproductibilite/application/tree/appli19/index.qmd) et retirer `about.qmd` des fichiers à compiler.\n",
        "- Déplacer `styles.css` à la racine du projet\n",
        "- Mettre à jour le `.gitignore` avec les instructions suivantes\n",
        "\n",
        "```{.bash file=\".gitignore\" no-prefix=true}\n",
        "/.quarto/\n",
        "*.html\n",
        "*_files\n",
        "_site/\n",
        "```\n",
        "\n",
        "- En ligne de commande, faire `quarto preview` (ajouter les arguments `--port 5000 --host 0.0.0.0` si vous passez par le `SSPCloud`)\n",
        "- Observer le site web généré en local\n",
        "\n",
        "Enfin, on va construire et déployer automatiquement ce site web grâce au\n",
        "combo `Github Actions` et `Github Pages`:\n",
        "\n",
        "- Créer une branche `gh-pages` à partir des lignes suivantes\n",
        "\n",
        "```python\n",
        "git checkout --orphan gh-pages\n",
        "git reset --hard # make sure all changes are committed before running this!\n",
        "git commit --allow-empty -m \"Initialising gh-pages branch\"\n",
        "git push origin gh-pages\n",
        "```\n",
        "\n",
        "- Revenir à votre branche\n",
        "- Créer un fichier `.github/workflows/website.yaml` avec le contenu de [ce fichier](https://raw.githubusercontent.com/ensae-reproductibilite/application/tree/appli20/.github/workflows/publish.yaml)\n",
        "- Modifier le `README` pour indiquer l'URL de votre site web et de votre API\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli20\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Partie 6: adopter une approche MLOps pour améliorer notre modèle\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Si vous prenez ce projet fil rouge en cours de route\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git checkout appli20\n",
        "git checkout -b dev\n",
        "git push origin dev\n",
        "```\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "Maintenant que nous avons tout préparé pour mettre à disposition rapidement un modèle,\n",
        "nous pouvons revenir en arrière pour améliorer ce modèle. Pour cela, nous allons mettre en oeuvre une validation croisée.\n",
        "\n",
        "Le problème que nous allons rencontrer va être que nous voudrions facilement tracer les évolutions de notre modèle, la qualité prédictive de celui-ci dans différentes situations. Il s'agira d'à nouveau mettre en place du _logging_ mais, cette fois, de suivre la qualité du modèle et pas seulement s'il fonctionne. L'outil `MLFlow` va répondre à ce problème et va, au passage, fluidifier la mise à disposition du modèle de production, c'est-à-dire de celui qu'on désire mettre à disposition du public.\n",
        "\n",
        "## Revenir sur le code d'entraînement du modèle pour faire de la validation croisée\n",
        "\n",
        "Pour pouvoir faire ceci, il va falloir changer un tout petit peu notre code applicatif dans sa phase d'entraînement.\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Application 21 _(optionnelle)_: restructuration de la chaîne\n",
        "\n",
        "1. Faire les modifications suivantes pour restructurer notre _pipeline_\n",
        "afin de mieux distinguer les étapes d'estimation et d'évaluation\n",
        "\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "Modification de `train.py` pour faire une _grid search_\n",
        "</summary>\n",
        "\n",
        "```{.python filename=\"train.py\"}\n",
        "\"\"\"\n",
        "Prediction de la survie d'un individu sur le Titanic\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import argparse\n",
        "from loguru import logger\n",
        "\n",
        "import pathlib\n",
        "from joblib import dump\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from src.pipeline.build_pipeline import split_train_test, create_pipeline\n",
        "from src.models.train_evaluate import evaluate_model\n",
        "\n",
        "\n",
        "# ENVIRONMENT CONFIGURATION ---------------------------\n",
        "\n",
        "logger.add(\"recording.log\", rotation=\"500 MB\")\n",
        "load_dotenv()\n",
        "\n",
        "parser = argparse.ArgumentParser(description=\"Paramètres du random forest\")\n",
        "parser.add_argument(\n",
        "    \"--n_trees\", type=int, default=20, help=\"Nombre d'arbres\"\n",
        ")\n",
        "args = parser.parse_args()\n",
        "\n",
        "URL_RAW = \"https://minio.lab.sspcloud.fr/lgaliana/ensae-reproductibilite/data/raw/data.csv\"\n",
        "\n",
        "n_trees = args.n_trees\n",
        "jeton_api = os.environ.get(\"JETON_API\", \"\")\n",
        "data_path = os.environ.get(\"data_path\", URL_RAW)\n",
        "data_train_path = os.environ.get(\"train_path\", \"data/derived/train.parquet\")\n",
        "data_test_path = os.environ.get(\"test_path\", \"data/derived/test.parquet\")\n",
        "MAX_DEPTH = None\n",
        "MAX_FEATURES = \"sqrt\"\n",
        "\n",
        "if jeton_api.startswith(\"$\"):\n",
        "    logger.info(\"API token has been configured properly\")\n",
        "else:\n",
        "    logger.warning(\"API token has not been configured\")\n",
        "\n",
        "\n",
        "# IMPORT ET STRUCTURATION DONNEES --------------------------------\n",
        "\n",
        "p = pathlib.Path(\"data/derived/\")\n",
        "p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "TrainingData = pd.read_csv(data_path)\n",
        "\n",
        "X_train, X_test, y_train, y_test = split_train_test(\n",
        "    TrainingData, test_size=0.1,\n",
        "    train_path=data_train_path,\n",
        "    test_path=data_test_path\n",
        ")\n",
        "\n",
        "\n",
        "# PIPELINE ----------------------------\n",
        "\n",
        "\n",
        "# Create the pipeline\n",
        "pipe = create_pipeline(\n",
        "    n_trees, max_depth=MAX_DEPTH, max_features=MAX_FEATURES\n",
        ")\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    \"classifier__n_estimators\": [10, 20, 50],\n",
        "    \"classifier__max_leaf_nodes\": [5, 10, 50],\n",
        "}\n",
        "\n",
        "\n",
        "pipe_cross_validation = GridSearchCV(\n",
        "    pipe,\n",
        "    param_grid=param_grid,\n",
        "    scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\"],\n",
        "    refit=\"f1\",\n",
        "    cv=5,\n",
        "    n_jobs=5,\n",
        "    verbose=1,\n",
        ")\n",
        "pipe = pipe_cross_validation.best_estimator_\n",
        "\n",
        "# ESTIMATION ET EVALUATION ----------------------\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "dump(pipe, 'model.joblib')\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "score, matrix = evaluate_model(pipe, X_test, y_test)\n",
        "\n",
        "logger.success(f\"{score:.1%} de bonnes réponses sur les données de test pour validation\")\n",
        "logger.debug(20 * \"-\")\n",
        "logger.info(\"Matrice de confusion\")\n",
        "logger.debug(matrix)\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "2. Dans le code de l'API (`api/main.py`), changer la version du modèle mis en oeuvre en _\"0.2\"_\n",
        "2. Après avoir committé cette nouvelle version du code applicatif, tagguer ce dépôt avec le tag `v0.0.2`\n",
        "3. Modifier `deployment/deployment.yaml` dans le code `GitOps` pour utiliser ce _tag_.\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli21\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Garder une trace des entraînements de notre modèle grâce au _register_ de `MLFlow`\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Si vous prenez ce projet fil rouge en cours de route\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash\n",
        "git checkout appli21\n",
        "```\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "## Enregistrer nos premiers entraînements\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Application 22 : archiver nos entraînements avec `MLFlow`\n",
        "\n",
        "1. Lancer `MLFlow` depuis l'onflet [Mes services](https://datalab.sspcloud.fr/catalog/automation) du SSPCloud.\n",
        "Attendre que le service soit bien lancé.\n",
        "Cela créera un service dont l'URL est de la forme `https://user-{username}.user.lab.sspcloud.fr`. Ce service `MLFlow` communiquera avec les `VSCode` que vous\n",
        "ouvrirez ultérieurement à partir de cet URL ainsi qu'avec le système de stockage `S3`[^tokenMLFlow].\n",
        "\n",
        "1. Regarder la page `Experiments`. Elle ne contient que `Default` à ce stade, c'est normal.\n",
        "\n",
        "[^tokenMLFlow]: Par conséquent, `MLFLow` bénéficie de l'injection automatique des _tokens_\n",
        "pour pouvoir lire/écrire sur S3. Ces jetons ont la même durée avant expiration que ceux\n",
        "de vos services interactifs `VSCode`. Il faut donc, par défaut, supprimer et rouvrir un service `MLFLow`\n",
        "régulièrement. La manière d'éviter cela\n",
        "est de créer des _service account_ sur [https://minio-console.lab.sspcloud.fr/](https://minio-console.lab.sspcloud.fr/login)\n",
        "et de les renseigner sur [la page](https://datalab.sspcloud.fr/project-settings/s3-configs).\n",
        "\n",
        "\n",
        "2. Une fois le service `MLFlow` fonctionnel,\n",
        "lancer un nouveau `VSCode` pour bénéficier de la connexion\n",
        "automatique entre les services interactifs du SSPCloud et les services d'automatisation comme `MLFlow`.\n",
        "\n",
        "1. Clôner votre projet, vous situer sur la branche de travail.\n",
        "\n",
        "2. Dans la section de passage des paramètres de notre ligne de commande, introduire ce morceau de code:\n",
        "\n",
        "```{.python}\n",
        "parser = argparse.ArgumentParser(description=\"Paramètres du random forest\")\n",
        "parser.add_argument(\n",
        "    \"--n_trees\", type=int, default=20, help=\"Nombre d'arbres\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--experiment_name\", type=str, default=\"titanicml\", help=\"MLFlow experiment name\"\n",
        ")\n",
        "args = parser.parse_args()\n",
        "```\n",
        "\n",
        "3. Faire tourner `train.py` en ligne de commande puis retourner sur l'UI de `MLFlow`\n",
        "et observer la différence, à gauche.\n",
        "\n",
        "4. A la fin du script `train.py`, ajouter le code suivant\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "Code à ajouter\n",
        "</summary>\n",
        "\n",
        "```{.python filename=\"fin de train.py\"}\n",
        "# LOGGING IN MLFLOW -----------------\n",
        "\n",
        "input_data_mlflow = mlflow.data.from_pandas(\n",
        "    TrainingData, source=data_path, name=\"Raw dataset\"\n",
        ")\n",
        "training_data_mlflow = mlflow.data.from_pandas(\n",
        "    pd.concat([X_train, y_train]), source=data_path, name=\"Training data\"\n",
        ")\n",
        "\n",
        "\n",
        "with mlflow.start_run():\n",
        "\n",
        "    # Log datasets\n",
        "    mlflow.log_input(input_data_mlflow, context=\"raw\")\n",
        "    mlflow.log_input(training_data_mlflow, context=\"raw\")\n",
        "\n",
        "    # Log parameters\n",
        "    mlflow.log_param(\"n_trees\", n_trees)\n",
        "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
        "    mlflow.log_param(\"max_features\", MAX_FEATURES)\n",
        "\n",
        "    # Log best hyperparameters from GridSearchCV\n",
        "    best_params = pipe_cross_validation.best_params_\n",
        "    for param, value in best_params.items():\n",
        "        mlflow.log_param(param, value)\n",
        "\n",
        "    # Log metrics\n",
        "    mlflow.log_metric(\"accuracy\", score)\n",
        "\n",
        "    # Log confusion matrix as an artifact\n",
        "    matrix_path = \"confusion_matrix.txt\"\n",
        "    with open(matrix_path, \"w\") as f:\n",
        "        f.write(str(matrix))\n",
        "    mlflow.log_artifact(matrix_path)\n",
        "\n",
        "    # Log model\n",
        "    mlflow.sklearn.log_model(pipe, \"model\")\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "5. Ajouter `mlruns/*` dans `.gitignore`\n",
        "\n",
        "6. Tester `train.py` en ligne de commande\n",
        "\n",
        "7. Observer l'évolution de la page `Experiments`. Cliquer sur un des _run_.\n",
        "Observer toutes les métadonnées archivées (hyperparamètres, métriques d'évaluation, `requirements.txt` dont `MLFlow` a fait l'inférence, etc.)\n",
        "\n",
        "1. Observer le code proposé par `MLFlow` pour récupérer le _run_ en question. Tester celui-ci dans un _notebook_ sur le fichier intermédiaire de test au format `Parquet`\n",
        "\n",
        "2.  En ligne de commande, faites tourner pour une autre valeur de `n_trees`.  Retourner à la liste des _runs_ en cliquant à nouveau sur _\"titanicml\"_ dans les expérimentations\n",
        "\n",
        "3.  Dans l'onglet `Table`, sélectionner plusieurs expérimentations, cliquer sur `Columns` et ajouter la statistique d'accuracy. Ajuster la taille des colonnes pour la voir et classer les modèles par score décroissants\n",
        "\n",
        "4.  Cliquer sur `Compare` après en avoir sélectionné plusieurs. Afficher un _scatterplot_ des performances\n",
        "en fonction du nombre d'estimateurs. Conclure.\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli22\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Cette appplication illustre l'un des premiers apports de `MLFlow`: on garde\n",
        "une trace de nos expérimentations: le modèle est archivé avec les paramètres et des métriques de performance. On peut donc retrouver de plusieurs manières un modèle qui nous avait tapé dans l'oeil.\n",
        "\n",
        "Néanmoins, persistent un certain nombre de voies d'amélioration dans notre _pipeline_.\n",
        "\n",
        "- On entraîne le modèle en local, de manière séquentielle, et en lançant nous-mêmes le script `train.py`.\n",
        "- Pis encore, à l'heure actuelle, cette étape d'estimation n'est pas séparée de la mise à disposition du modèle par le biais de notre API. On archive des modèles mais on les utilise pas ultérieurement.\n",
        "\n",
        "\n",
        "Les prochaines applications permettront d'améliorer ceci.\n",
        "\n",
        "## Consommation d'un modèle archivé sur `MLFlow`\n",
        "\n",
        "A l'heure actuelle, notre _pipeline_ est linéaire:\n",
        "\n",
        "![](/chapters/applications/figures/pipeline_avant_appli23.png)\n",
        "\n",
        "Ceci nous gêne pour faire évoluer notre modèle: on ne dissocie pas ce qui relève de l'entraînement du modèle de son utilisation. Un _pipeline_ plus cyclique permettra de mieux dissocier l'expérimentation de la production:\n",
        "\n",
        "![](/chapters/applications/figures/pipeline_apres_appli23.png)\n",
        "\n",
        "\n",
        "__TO BE CONTINUED__\n",
        "\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Application 23 : passer en production un modèle avec MLFlow\n",
        "\n",
        "1. A partir du tableau de performance précédent,\n",
        "choisir le modèle avec le F1 score maximal.\n",
        "Accéder à celui-ci.\n",
        "\n",
        "Créer un script dans `mlflow/predict.py` pour\n",
        "illustrer l'utilisation d'un modèle\n",
        "depuis MLFlow. Nous allons progressivement l'améliorer.\n",
        "\n",
        "1. Copier-coller le\n",
        "contenu ci-dessous\n",
        "afin de se simplifier la création de données en entrée\n",
        "de notre code\n",
        "\n",
        "```{.python filename=\"data/import_data.py\"}\n",
        "import data\n",
        "\n",
        "@logger.catch\n",
        "def create_data(\n",
        "    sex: str = \"female\",\n",
        "    age: float = 29.0,\n",
        "    fare: float = 16.5,\n",
        "    embarked: str = \"S\",\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.DataFrame(\n",
        "        {\n",
        "            \"Sex\": [sex],\n",
        "            \"Age\": [age],\n",
        "            \"Fare\": [fare],\n",
        "            \"Embarked\": [embarked],\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return df\n",
        "```\n",
        "\n",
        "2. Alléger, au passage, le code de l'API, en modifiant la fonction `predict` par celle-ci:\n"
      ],
      "id": "d3cab952"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from src.data.import_data import create_data\n",
        "\n",
        "async def predict(\n",
        "    sex: str = \"female\",\n",
        "    age: float = 29.0,\n",
        "    fare: float = 16.5,\n",
        "    embarked: str = \"S\"\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    df = create_data(\n",
        "        sex=sex,\n",
        "        age=age,\n",
        "        fare=fare,\n",
        "        embarked=embarked\n",
        "    )\n",
        "\n",
        "    prediction = \"Survived 🎉\" if int(model.predict(df)) == 1 else \"Dead ⚰️\"\n",
        "\n",
        "    return prediction"
      ],
      "id": "5cd5edcb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Par le biais \n",
        "\n",
        "6. Cliquer sur votre meilleur modèle et introduire dans `mlflow/predict.py`\n",
        "le morceau de code suggéré\n",
        "par `MLFlow`, du type de celui-ci:\n"
      ],
      "id": "9213283b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "import mlflow\n",
        "logged_model = #A CHANGER #<1>\n",
        "\n",
        "# Load model as a PyFuncModel.\n",
        "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
        "\n",
        "# Predict on a Pandas DataFrame.\n",
        "import pandas as pd\n",
        "loaded_model.predict(pd.DataFrame(data))"
      ],
      "id": "a91d1f34",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. _Hash_ du modèle\n",
        "\n",
        "Lancer depuis la ligne de commande ce script et observer l'application obtenue.\n",
        "\n",
        ":::\n",
        "\n",
        "A ce stade, nous avons amélioré la fiabilité de notre modèle car\n",
        "nous utilisons le meilleur. Néanmoins, celui-ci\n",
        "n'est pas forcément pratique à récupérer car nous utilisons\n",
        "un _hash_ qui certes identifie de manière unique notre modèle\n",
        "mais présente l'inconvénient d'être peu intelligible.\n",
        "Nous allons passer de l'expérimentation à la mise\n",
        "en production en sélectionnant explicitement notre meilleur modèle.\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Application 23b : passer en production un modèle\n",
        "\n",
        "1. Dans la page du modèle en question sur `MLFlow`, cliquer sur `Register model`\n",
        "et le nommer `titanic`.\n",
        "2. Aller dans l'onglet `Models` et observer le changement par rapport à précédemment.\n",
        "3. Mettre à jour le code dans `mlflow/predict.py` pour utiliser la version en\n",
        "production :\n",
        "\n",
        "```{.python filename = \"mlflow/predict.py\"}\n",
        "model_name = \"titanic\"\n",
        "model_version = 1\n",
        "loaded_model = mlflow.pyfunc.load_model(\n",
        "    model_uri=f\"models:/{model_name}/{model_version}\"\n",
        ")\n",
        "```\n",
        "\n",
        "4. Tester cette application. Si celle-ci fonctionne,\n",
        "modifier la récupération du modèle dans votre script d'API.\n",
        "\n",
        "5. Tester en local cette API mise à jour\n",
        "\n",
        "```{.shell filename=\"terminal\"}\n",
        "uvicorn api.main:app --reload --host \"0.0.0.0\" --port 5000\n",
        "```\n",
        "\n",
        "6. Ajouter `mlflow` au `requirements.txt`\n",
        "\n",
        "7. Mettre à jour\n",
        "les fichiers `.github/worflows/prod.yaml` et `kubernetes/deployment.yaml`\n",
        "pour produire et utiliser le tag `v0.0.5`\n"
      ],
      "id": "6930e7d8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "filename": ".github/worflows/prod.yaml",
        "file": ".github/worflows/prod.yaml"
      },
      "source": [
        "#| eval: false\n",
        "\n",
        "name: Construction image Docker\n",
        "\n",
        "on:\n",
        "  push:\n",
        "    branches:\n",
        "      - main\n",
        "      - dev\n",
        "\n",
        "jobs:\n",
        "  docker:\n",
        "    runs-on: ubuntu-latest\n",
        "    steps:\n",
        "      -\n",
        "        name: Set up QEMU\n",
        "        uses: docker/setup-qemu-action@v3\n",
        "      -\n",
        "        name: Set up Docker Buildx\n",
        "        uses: docker/setup-buildx-action@v3\n",
        "      -\n",
        "        name: Login to Docker Hub\n",
        "        uses: docker/login-action@v3\n",
        "        with:\n",
        "          username: ${{ secrets.DOCKERHUB_USERNAME }}\n",
        "          password: ${{ secrets.DOCKERHUB_TOKEN }}\n",
        "      -\n",
        "        name: Build and push\n",
        "        uses: docker/build-push-action@v5\n",
        "        with:\n",
        "          push: true\n",
        "          tags: linogaliana/application:v0.0.7 #<1>"
      ],
      "id": "39635fff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Modifier l'image ici\n"
      ],
      "id": "474859aa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Creating MLflow deployment\n",
        "apiVersion: apps/v1\n",
        "kind: Deployment\n",
        "metadata:\n",
        "  name: titanicml\n",
        "spec:\n",
        "  replicas: 1\n",
        "  selector:\n",
        "    matchLabels:\n",
        "      app: titanicml\n",
        "  template:\n",
        "    metadata:\n",
        "      labels:\n",
        "        app: titanicml\n",
        "    spec:\n",
        "      containers:\n",
        "        - name: api\n",
        "          image: linogaliana/application:v0.0.7 #<1>\n",
        "          imagePullPolicy: Always\n",
        "          env:\n",
        "            - name: MLFLOW_TRACKING_URI\n",
        "              value: https://user-{USERNAME}-mlflow.user.lab.sspcloud.fr #<2>\n",
        "            - name: MLFLOW_MODEL_NAME\n",
        "              value: titanic\n",
        "            - name: MLFLOW_MODEL_VERSION\n",
        "              value: \"1\"\n",
        "          resources:\n",
        "            limits:\n",
        "              memory: \"2Gi\"\n",
        "              cpu: \"1000m\""
      ],
      "id": "387f7fb7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Modifier l'image `Docker`\n",
        "2. Modifier l'URL de `MLFlow`\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "::: {.callout-caution collapse=\"true\"}\n",
        "## Checkpoint\n",
        "\n",
        "```{.bash filename=\"terminal\"}\n",
        "git stash #<1>\n",
        "git checkout appli23\n",
        "```\n",
        "1. Pour annuler les modifications depuis le dernier _commit_\n",
        "\n",
        "\n",
        "![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "\n",
        "### Industrialiser les entraînements de nos modèles\n",
        "\n",
        "Pour industrialiser nos entraînements, nous allons créer des processus\n",
        "parallèles indépendants pour chaque combinaison de nos hyperparamètres.\n",
        "Pour cela, l'outil pratique sur le SSPCloud est `Argo workflows`.\n",
        "Chaque combinaison d'hyperparamètres sera un processus isolé à l'issue duquel sera\n",
        "loggué le résultat dans `MLFlow`. Ces entraînements auront lieu en parallèle.\n",
        "\n",
        "\n",
        "![](https://inseefrlab.github.io/formation-mlops/slides/img/pokemon_workflow.png)\n",
        "\n",
        "\n",
        "1. Lancer un service Argo Workflows\n",
        "2. Dans `mlflow/training.yaml`\n"
      ],
      "id": "66fe1e68"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "apiVersion: argoproj.io/v1alpha1\n",
        "kind: Workflow\n",
        "metadata:\n",
        "  generateName: titanic-training-workflow-\n",
        "spec:\n",
        "  entrypoint: main\n",
        "  arguments:\n",
        "    parameters:\n",
        "      # The MLflow tracking server is responsible to log the hyper-parameter and model metrics.\n",
        "      - name: mlflow-tracking-uri\n",
        "        value: https://user-lgaliana-argo-workflows.user.lab.sspcloud.fr #<1>\n",
        "      - name: mlflow-experiment-name\n",
        "        value: titanicml #<2>\n",
        "      - name: model-training-conf-list\n",
        "        value: |\n",
        "          [\n",
        "            { \"dim\": 25, \"lr\": 0.1 },\n",
        "            { \"dim\": 100, \"lr\": 0.2 },\n",
        "            { \"dim\": 150, \"lr\": 0.3 }\n",
        "          ]\n",
        "  templates:\n",
        "    # Entrypoint DAG template\n",
        "    - name: main\n",
        "      dag:\n",
        "        tasks:\n",
        "          # Task 0: Start pipeline\n",
        "          - name: start-pipeline\n",
        "            template: start-pipeline-wt\n",
        "          # Task 1: Train model with given params\n",
        "          - name: train-model-with-params\n",
        "            dependencies: [ start-pipeline ]\n",
        "            template: run-model-training-wt\n",
        "            arguments:\n",
        "              parameters:\n",
        "                - name: dim\n",
        "                  value: \"{{item.dim}}\"\n",
        "                - name: lr\n",
        "                  value: \"{{item.lr}}\"\n",
        "            # Pass the inputs to the task using \"withParam\"\n",
        "            withParam: \"{{workflow.parameters.model-training-conf-list}}\"\n",
        "\n",
        "    # Now task container templates are defined\n",
        "    # Worker template for task 0 : start-pipeline\n",
        "    - name: start-pipeline-wt\n",
        "      inputs:\n",
        "      container:\n",
        "        image: busybox\n",
        "        command: [ sh, -c ]\n",
        "        args: [ \"echo Starting pipeline\" ]\n",
        "\n",
        "    # Worker template for task-1 : train model with params\n",
        "    - name: run-model-training-wt\n",
        "      inputs:\n",
        "        parameters:\n",
        "          - name: dim\n",
        "          - name: lr\n",
        "      container:\n",
        "        image: inseefrlab/formation-mlops:main\n",
        "        imagePullPolicy: Always\n",
        "        command: [sh, -c]\n",
        "        args: [\"mlflow run .\n",
        "                --env-manager=local\n",
        "                -P remote_server_uri=$MLFLOW_TRACKING_URI\n",
        "                -P experiment_name=$MLFLOW_EXPERIMENT_NAME\n",
        "                -P dim={{inputs.parameters.dim}}\n",
        "                -P lr={{inputs.parameters.lr}}\"]\n",
        "        env:\n",
        "          - name: MLFLOW_TRACKING_URI\n",
        "            value: \"{{workflow.parameters.mlflow-tracking-uri}}\"\n",
        "          - name: MLFLOW_EXPERIMENT_NAME\n",
        "            value: \"{{workflow.parameters.mlflow-experiment-name}}\""
      ],
      "id": "9581f1c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Changer\n",
        "2. `titanicml`\n",
        "\n",
        "max_depth\n",
        "\n",
        "max_features “sqrt”, “log2”\n",
        "\n",
        "## Pour aller plus loin\n",
        "\n",
        "Créer un service label studio pour évaluer la qualité du modèle"
      ],
      "id": "3b4ac959"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/opt/conda/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}